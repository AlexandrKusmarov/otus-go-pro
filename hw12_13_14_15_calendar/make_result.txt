$ make integration-tests
docker-compose -f .\docker-compose.integra.yml up
[+] Running 6/0
 ✔ Container hw12_13_14_15_calendar-kafka-1     Created                                                                                                                                                                        0.0s
 ✔ Container hw12_13_14_15_calendar-postgres-1  Created                                                                                                                                                                        0.0s
 ✔ Container calendar-sender                    Created                                                                                                                                                                        0.0s
 ✔ Container calendar-scheduler                 Created                                                                                                                                                                        0.0s
 ✔ Container calendar-app                       Created                                                                                                                                                                        0.0s
 ✔ Container integration_tests                  Created                                                                                                                                                                        0.0s
Attaching to calendar-app, calendar-scheduler, calendar-sender, kafka-1, postgres-1, integration_tests
kafka-1             | kafka 17:14:30.30 INFO  ==>
kafka-1             | kafka 17:14:30.31 INFO  ==> Welcome to the Bitnami kafka container
postgres-1          |
kafka-1             | kafka 17:14:30.31 INFO  ==> Subscribe to project updates by watching https://github.com/bitnami/containers
postgres-1          | PostgreSQL Database directory appears to contain a database; Skipping initialization
kafka-1             | kafka 17:14:30.32 INFO  ==> Did you know there are enterprise versions of the Bitnami catalog? For enhanced secure software supply chain features, unlimited pulls from Docker, LTS support, or application cu
stomization, see Bitnami Premium or Tanzu Application Catalog. See https://www.arrow.com/globalecs/na/vendors/bitnami/ for more information.
postgres-1          |
kafka-1             | kafka 17:14:30.32 INFO  ==>
kafka-1             | kafka 17:14:30.32 INFO  ==> ** Starting Kafka setup **
postgres-1          | 2025-01-18 17:14:30.487 UTC [1] LOG:  starting PostgreSQL 17.2 (Debian 17.2-1.pgdg120+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 12.2.0-14) 12.2.0, 64-bit
postgres-1          | 2025-01-18 17:14:30.487 UTC [1] LOG:  listening on IPv4 address "0.0.0.0", port 5432
postgres-1          | 2025-01-18 17:14:30.487 UTC [1] LOG:  listening on IPv6 address "::", port 5432
postgres-1          | 2025-01-18 17:14:30.509 UTC [1] LOG:  listening on Unix socket "/var/run/postgresql/.s.PGSQL.5432"
postgres-1          | 2025-01-18 17:14:30.533 UTC [28] LOG:  database system was shut down at 2025-01-18 17:13:43 UTC
postgres-1          | 2025-01-18 17:14:30.555 UTC [1] LOG:  database system is ready to accept connections
kafka-1             | kafka 17:14:30.56 INFO  ==> Initializing KRaft storage metadata
kafka-1             | kafka 17:14:30.58 INFO  ==> Formatting storage directories to add metadata...
postgres-1          | 2025-01-18 17:14:31.269 UTC [32] ERROR:  database "calendar_db" already exists
postgres-1          | 2025-01-18 17:14:31.269 UTC [32] STATEMENT:  CREATE DATABASE calendar_db
calendar-app        | Миграция выполнена успешно.
calendar-app        | 2025/01/18 17:14:31 goose: no migrations to run. current version: 4
calendar-app        | &{0xc000276f60 2 true} &{0xc000130990}
calendar-app        | 2025/01/18 17:14:31 gRPC server is running on port :50051
calendar-app        | [INFO] 2025/01/18 17:14:31 calendar is running...
calendar-app        | [INFO] 2025/01/18 17:14:31 Starting server on calendar-app:8081...
kafka-1             | Picked up JAVA_TOOL_OPTIONS:
calendar-sender     | Ожидание сообщений...
calendar-scheduler  | &{0xc0002b9350 2 true} &{0xc0002b9440}
calendar-scheduler  | 2025/01/18 17:14:31 Ошибка подключения к Kafka: failed to dial: failed to open connection to kafka:9092: dial tcp 172.26.0.2:9092: connect: connection refused
integration_tests   | === RUN   TestIntegrationCreateEvent
integration_tests   | --- PASS: TestIntegrationCreateEvent (0.04s)
integration_tests   | === RUN   TestIntegrationCreateEventWithoutDescription
integration_tests   | --- PASS: TestIntegrationCreateEventWithoutDescription (7.03s)
integration_tests   | === RUN   TestIntegrationCreateMultipleEvents
integration_tests   | --- PASS: TestIntegrationCreateMultipleEvents (0.03s)
integration_tests   | PASS
integration_tests   | ok        github.com/AlexandrKusmarov/otus-go-pro/hw12_13_14_15_calendar/integration_test (cached)
kafka-1             | All of the log directories are already formatted.
calendar-scheduler exited with code 0
integration_tests exited with code 0
kafka-1             | kafka 17:14:34.31 INFO  ==> ** Kafka setup finished! **
kafka-1             |
kafka-1             | kafka 17:14:34.34 INFO  ==> ** Starting Kafka **
kafka-1             | Picked up JAVA_TOOL_OPTIONS:
calendar-scheduler  | 2025/01/18 17:14:35 Ошибка подключения к Kafka: failed to dial: failed to open connection to kafka:9092: dial tcp 172.26.0.2:9092: connect: connection refused
calendar-scheduler exited with code 0
kafka-1             | [2025-01-18 17:14:36,642] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
kafka-1             | [2025-01-18 17:14:37,441] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
kafka-1             | [2025-01-18 17:14:38,005] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
kafka-1             | [2025-01-18 17:14:38,018] INFO [ControllerServer id=1] Starting controller (kafka.server.ControllerServer)
calendar-scheduler exited with code 0
kafka-1             | [2025-01-18 17:14:39,663] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
kafka-1             | [2025-01-18 17:14:39,802] INFO [SocketServer listenerType=CONTROLLER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(CONTROLLER) (kafka.network.SocketServer)
kafka-1             | [2025-01-18 17:14:39,812] INFO CONTROLLER: resolved wildcard host to eb5434ea967b (org.apache.kafka.metadata.ListenerInfo)
kafka-1             | [2025-01-18 17:14:39,835] INFO authorizerStart completed for endpoint CONTROLLER. Endpoint is now READY. (org.apache.kafka.server.network.EndpointReadyFutures)
kafka-1             | [2025-01-18 17:14:39,848] INFO [SharedServer id=1] Starting SharedServer (kafka.server.SharedServer)
kafka-1             | [2025-01-18 17:14:40,060] INFO [LogLoader partition=__cluster_metadata-0, dir=/bitnami/kafka/data] Recovering unflushed segment 0. 0/1 recovered for __cluster_metadata-0. (kafka.log.LogLoader)
kafka-1             | [2025-01-18 17:14:40,064] INFO [LogLoader partition=__cluster_metadata-0, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:40,067] INFO [LogLoader partition=__cluster_metadata-0, dir=/bitnami/kafka/data] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:40,068] INFO Deleted producer state snapshot /bitnami/kafka/data/__cluster_metadata-0/00000000000000062261.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
kafka-1             | [2025-01-18 17:14:40,068] INFO Deleted producer state snapshot /bitnami/kafka/data/__cluster_metadata-0/00000000000000062592.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
kafka-1             | [2025-01-18 17:14:40,068] INFO [LogLoader partition=__cluster_metadata-0, dir=/bitnami/kafka/data] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.Un
ifiedLog$)
kafka-1             | [2025-01-18 17:14:40,561] INFO [ProducerStateManager partition=__cluster_metadata-0] Wrote producer snapshot at offset 62592 with 0 producer ids in 8 ms. (org.apache.kafka.storage.internals.log.ProducerStat
eManager)
kafka-1             | [2025-01-18 17:14:40,589] INFO [LogLoader partition=__cluster_metadata-0, dir=/bitnami/kafka/data] Loading producer state till offset 62592 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:40,589] INFO [LogLoader partition=__cluster_metadata-0, dir=/bitnami/kafka/data] Reloading from producer snapshot and rebuilding producer state from offset 62592 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:40,590] INFO [ProducerStateManager partition=__cluster_metadata-0] Loading producer state from snapshot file 'SnapshotFile(offset=62592, file=/bitnami/kafka/data/__cluster_metadata-0/00000
000000000062592.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
kafka-1             | [2025-01-18 17:14:40,596] INFO [LogLoader partition=__cluster_metadata-0, dir=/bitnami/kafka/data] Producer state recovery took 6ms for snapshot load and 0ms for segment recovery from offset 62592 (kafka.lo
g.UnifiedLog$)
calendar-scheduler  | &{0xc000253110 2 true} &{0xc000253200}
calendar-scheduler  | 2025/01/18 17:08:16 Ошибка подключения к Kafka: failed to dial: failed to open connection to kafka:9092: dial tcp 172.26.0.2:9092: connect: connection refused
calendar-scheduler  | &{0xc0002572f0 2 true} &{0xc0002573e0}
calendar-scheduler exited with code 1
calendar-scheduler  | 2025/01/18 17:08:19 Ошибка подключения к Kafka: failed to dial: failed to open connection to kafka:9092: dial tcp 172.26.0.2:9092: connect: connection refused
calendar-scheduler  | &{0xc0002ab230 2 true} &{0xc0002ab320}
calendar-scheduler  | 2025/01/18 17:08:21 Ошибка подключения к Kafka: failed to dial: failed to open connection to kafka:9092: dial tcp 172.26.0.2:9092: connect: connection refused
calendar-scheduler  | &{0xc00027d2f0 2 true} &{0xc00027d3e0}
calendar-scheduler  | 2025/01/18 17:08:23 Ошибка подключения к Kafka: failed to dial: failed to open connection to kafka:9092: dial tcp 172.26.0.2:9092: connect: connection refused
calendar-scheduler  | &{0xc0001ed320 2 true} &{0xc0001ed410}
calendar-scheduler  | 2025/01/18 17:08:25 Ошибка подключения к Kafka: failed to dial: failed to open connection to kafka:9092: dial tcp 172.26.0.2:9092: connect: connection refused
kafka-1             | [2025-01-18 17:14:40,719] INFO Initialized snapshots with IDs Set(OffsetAndEpoch(offset=14549, epoch=11), OffsetAndEpoch(offset=28968, epoch=13), OffsetAndEpoch(offset=36848, epoch=14), OffsetAndEpoch(offse
t=44047, epoch=14)) from /bitnami/kafka/data/__cluster_metadata-0 (kafka.raft.KafkaMetadataLog$)
calendar-scheduler  | &{0xc000253110 2 true} &{0xc000253200}
calendar-scheduler  | &{0xc0002d72f0 2 true} &{0xc0002d73e0}
calendar-scheduler exited with code 1
calendar-scheduler  | 2025/01/18 17:08:16 Ошибка подключения к Kafka: failed to dial: failed to open connection to kafka:9092: dial tcp 172.26.0.2:9092: connect: connection refused
calendar-scheduler  | 2025/01/18 17:08:29 Ошибка подключения к Kafka: failed to dial: failed to open connection to kafka:9092: dial tcp 172.26.0.2:9092: connect: connection refused
calendar-scheduler  | &{0xc0002572f0 2 true} &{0xc0002573e0}
kafka-1             | [2025-01-18 17:14:40,771] INFO [raft-expiration-reaper]: Starting (kafka.raft.TimingWheelExpirationService$ExpiredOperationReaper)
calendar-scheduler  | &{0xc000255cb0 2 true} &{0xc000255da0}
calendar-scheduler  | 2025/01/18 17:08:19 Ошибка подключения к Kafka: failed to dial: failed to open connection to kafka:9092: dial tcp 172.26.0.2:9092: connect: connection refused
calendar-scheduler  | 2025/01/18 17:08:34 Ошибка подключения к Kafka: failed to dial: failed to open connection to kafka:9092: dial tcp 172.26.0.2:9092: connect: connection refused
calendar-scheduler  | &{0xc0002ab230 2 true} &{0xc0002ab320}
calendar-scheduler  | &{0xc000205320 2 true} &{0xc000205410}
calendar-scheduler  | 2025/01/18 17:08:21 Ошибка подключения к Kafka: failed to dial: failed to open connection to kafka:9092: dial tcp 172.26.0.2:9092: connect: connection refused
calendar-scheduler  | Топик успешно создан!
calendar-scheduler  | &{0xc00027d2f0 2 true} &{0xc00027d3e0}
kafka-1             | [2025-01-18 17:14:40,842] INFO [RaftManager id=1] Reading KRaft snapshot and log as part of the initialization (org.apache.kafka.raft.KafkaRaftClient)
calendar-scheduler  | [INFO] 2025/01/18 17:08:43 Сервис по очистке старых событий запущен
calendar-scheduler  | 2025/01/18 17:08:23 Ошибка подключения к Kafka: failed to dial: failed to open connection to kafka:9092: dial tcp 172.26.0.2:9092: connect: connection refused
kafka-1             | [2025-01-18 17:14:40,847] INFO [RaftManager id=1] Loading snapshot (OffsetAndEpoch(offset=44047, epoch=14)) since log start offset (0) is greater than the internal listener's next offset (-1) (org.apache.ka
fka.raft.internals.KRaftControlRecordStateMachine)
calendar-scheduler  | [INFO] 2025/01/18 17:08:53 Публикуем JSON:
calendar-scheduler  | &{0xc0001ed320 2 true} &{0xc0001ed410}
calendar-scheduler  | &{0xc000022210 2 true} &{0xc000022300}
calendar-scheduler  | 2025/01/18 17:08:25 Ошибка подключения к Kafka: failed to dial: failed to open connection to kafka:9092: dial tcp 172.26.0.2:9092: connect: connection refused
calendar-scheduler  | 2025/01/18 17:11:42 Ошибка подключения к Kafka: failed to dial: failed to open connection to kafka:9092: dial tcp 172.26.0.2:9092: connect: connection refused
calendar-scheduler  | &{0xc0002d72f0 2 true} &{0xc0002d73e0}
calendar-scheduler  | &{0xc000239350 2 true} &{0xc000239440}
calendar-scheduler  | 2025/01/18 17:08:29 Ошибка подключения к Kafka: failed to dial: failed to open connection to kafka:9092: dial tcp 172.26.0.2:9092: connect: connection refused
calendar-scheduler  | 2025/01/18 17:11:44 Ошибка подключения к Kafka: failed to dial: failed to open connection to kafka:9092: dial tcp 172.26.0.2:9092: connect: connection refused
calendar-scheduler  | &{0xc000255cb0 2 true} &{0xc000255da0}
calendar-scheduler  | &{0xc000239350 2 true} &{0xc000239440}
calendar-scheduler  | 2025/01/18 17:08:34 Ошибка подключения к Kafka: failed to dial: failed to open connection to kafka:9092: dial tcp 172.26.0.2:9092: connect: connection refused
calendar-scheduler  | 2025/01/18 17:11:46 Ошибка подключения к Kafka: failed to dial: failed to open connection to kafka:9092: dial tcp 172.26.0.2:9092: connect: connection refused
calendar-scheduler  | &{0xc000205320 2 true} &{0xc000205410}
calendar-scheduler  | &{0xc0001f5320 2 true} &{0xc0001f5410}
calendar-scheduler  | Топик успешно создан!
calendar-scheduler  | 2025/01/18 17:11:48 Ошибка подключения к Kafka: failed to dial: failed to open connection to kafka:9092: dial tcp 172.26.0.2:9092: connect: connection refused
calendar-scheduler  | [INFO] 2025/01/18 17:08:43 Сервис по очистке старых событий запущен
calendar-scheduler  | &{0xc000239350 2 true} &{0xc000239440}
calendar-scheduler  | [INFO] 2025/01/18 17:08:53 Публикуем JSON:
calendar-scheduler  | 2025/01/18 17:11:49 Ошибка подключения к Kafka: failed to dial: failed to open connection to kafka:9092: dial tcp 172.26.0.2:9092: connect: connection refused
calendar-scheduler  | &{0xc000022210 2 true} &{0xc000022300}
kafka-1             | [2025-01-18 17:14:41,160] INFO [RaftManager id=1] Starting voters are VoterSet(voters={1=VoterNode(voterKey=ReplicaKey(id=1, directoryId=Optional.empty), listeners=Endpoints(endpoints={ListenerName(CONTROLL
ER)=/127.0.0.1:9093}), supportedKRaftVersion=SupportedVersionRange[min_version:0, max_version:0])}) (org.apache.kafka.raft.KafkaRaftClient)
calendar-scheduler  | &{0xc00025d320 2 true} &{0xc00025d410}
calendar-scheduler  | 2025/01/18 17:11:42 Ошибка подключения к Kafka: failed to dial: failed to open connection to kafka:9092: dial tcp 172.26.0.2:9092: connect: connection refused
kafka-1             | [2025-01-18 17:14:41,162] INFO [RaftManager id=1] Starting request manager with static voters: [127.0.0.1:9093 (id: 1 rack: null)] (org.apache.kafka.raft.KafkaRaftClient)
calendar-scheduler  | 2025/01/18 17:11:53 Ошибка подключения к Kafka: failed to dial: failed to open connection to kafka:9092: dial tcp 172.26.0.2:9092: connect: connection refused
calendar-scheduler  | &{0xc000239350 2 true} &{0xc000239440}
calendar-scheduler  | &{0xc000229350 2 true} &{0xc000229440}
calendar-scheduler  | 2025/01/18 17:11:44 Ошибка подключения к Kafka: failed to dial: failed to open connection to kafka:9092: dial tcp 172.26.0.2:9092: connect: connection refused
calendar-scheduler  | Топик успешно создан!
calendar-scheduler  | &{0xc000239350 2 true} &{0xc000239440}
calendar-scheduler  | [INFO] 2025/01/18 17:11:57 Сервис по очистке старых событий запущен
calendar-scheduler  | 2025/01/18 17:11:46 Ошибка подключения к Kafka: failed to dial: failed to open connection to kafka:9092: dial tcp 172.26.0.2:9092: connect: connection refused
calendar-scheduler  | &{0xc0002b9350 2 true} &{0xc0002b9440}
calendar-scheduler  | &{0xc0001f5320 2 true} &{0xc0001f5410}
calendar-scheduler  | 2025/01/18 17:14:31 Ошибка подключения к Kafka: failed to dial: failed to open connection to kafka:9092: dial tcp 172.26.0.2:9092: connect: connection refused
calendar-scheduler  | 2025/01/18 17:11:48 Ошибка подключения к Kafka: failed to dial: failed to open connection to kafka:9092: dial tcp 172.26.0.2:9092: connect: connection refused
calendar-scheduler  | &{0xc000239350 2 true} &{0xc000239440}
calendar-scheduler  | &{0xc000239350 2 true} &{0xc000239440}
calendar-scheduler  | 2025/01/18 17:14:34 Ошибка подключения к Kafka: failed to dial: failed to open connection to kafka:9092: dial tcp 172.26.0.2:9092: connect: connection refused
calendar-scheduler  | 2025/01/18 17:11:49 Ошибка подключения к Kafka: failed to dial: failed to open connection to kafka:9092: dial tcp 172.26.0.2:9092: connect: connection refused
calendar-scheduler  | &{0xc0000aa1e0 2 true} &{0xc0000aa2d0}
calendar-scheduler  | &{0xc00025d320 2 true} &{0xc00025d410}
calendar-scheduler  | 2025/01/18 17:14:35 Ошибка подключения к Kafka: failed to dial: failed to open connection to kafka:9092: dial tcp 172.26.0.2:9092: connect: connection refused
calendar-scheduler  | 2025/01/18 17:11:53 Ошибка подключения к Kafka: failed to dial: failed to open connection to kafka:9092: dial tcp 172.26.0.2:9092: connect: connection refused
calendar-scheduler  | &{0xc00026d320 2 true} &{0xc00026d410}
calendar-scheduler  | &{0xc000229350 2 true} &{0xc000229440}
calendar-scheduler  | 2025/01/18 17:14:37 Ошибка подключения к Kafka: failed to dial: failed to open connection to kafka:9092: dial tcp 172.26.0.2:9092: connect: connection refused
calendar-scheduler  | Топик успешно создан!
calendar-scheduler  | &{0xc00020e1e0 2 true} &{0xc00020e2d0}
calendar-scheduler  | [INFO] 2025/01/18 17:11:57 Сервис по очистке старых событий запущен
calendar-scheduler  | 2025/01/18 17:14:39 Ошибка подключения к Kafka: failed to dial: failed to open connection to kafka:9092: dial tcp 172.26.0.2:9092: connect: connection refused
calendar-scheduler  | &{0xc0002b9350 2 true} &{0xc0002b9440}
calendar-scheduler  | 2025/01/18 17:14:31 Ошибка подключения к Kafka: failed to dial: failed to open connection to kafka:9092: dial tcp 172.26.0.2:9092: connect: connection refused
calendar-scheduler  | &{0xc000239350 2 true} &{0xc000239440}
calendar-scheduler  | 2025/01/18 17:14:34 Ошибка подключения к Kafka: failed to dial: failed to open connection to kafka:9092: dial tcp 172.26.0.2:9092: connect: connection refused
calendar-scheduler  | &{0xc0000aa1e0 2 true} &{0xc0000aa2d0}
calendar-scheduler  | 2025/01/18 17:14:35 Ошибка подключения к Kafka: failed to dial: failed to open connection to kafka:9092: dial tcp 172.26.0.2:9092: connect: connection refused
calendar-scheduler  | &{0xc00026d320 2 true} &{0xc00026d410}
calendar-scheduler  | 2025/01/18 17:14:37 Ошибка подключения к Kafka: failed to dial: failed to open connection to kafka:9092: dial tcp 172.26.0.2:9092: connect: connection refused
calendar-scheduler  | &{0xc00020e1e0 2 true} &{0xc00020e2d0}
calendar-scheduler  | 2025/01/18 17:14:39 Ошибка подключения к Kafka: failed to dial: failed to open connection to kafka:9092: dial tcp 172.26.0.2:9092: connect: connection refused
kafka-1             | [2025-01-18 17:14:41,741] INFO [RaftManager id=1] Attempting durable transition to ResignedState(localId=1, epoch=26, voters=[1], electionTimeoutMs=1136, unackedVoters=[], preferredSuccessors=[]) from null
(org.apache.kafka.raft.QuorumState)
kafka-1             | [2025-01-18 17:14:41,797] INFO [RaftManager id=1] Completed transition to ResignedState(localId=1, epoch=26, voters=[1], electionTimeoutMs=1136, unackedVoters=[], preferredSuccessors=[]) from null (org.apac
he.kafka.raft.QuorumState)
kafka-1             | [2025-01-18 17:14:41,804] INFO [RaftManager id=1] Attempting durable transition to CandidateState(localId=1, localDirectoryId=IjfzZ4aV_jauVtbEs6etYA,epoch=27, retries=1, voteStates={1=org.apache.kafka.raft.
CandidateState$VoterState@37191ef0}, highWatermark=Optional.empty, electionTimeoutMs=1536) from ResignedState(localId=1, epoch=26, voters=[1], electionTimeoutMs=1136, unackedVoters=[], preferredSuccessors=[]) (org.apache.kafka.r
aft.QuorumState)
kafka-1             | [2025-01-18 17:14:41,821] INFO [RaftManager id=1] Completed transition to CandidateState(localId=1, localDirectoryId=IjfzZ4aV_jauVtbEs6etYA,epoch=27, retries=1, voteStates={1=org.apache.kafka.raft.Candidate
State$VoterState@37191ef0}, highWatermark=Optional.empty, electionTimeoutMs=1536) from ResignedState(localId=1, epoch=26, voters=[1], electionTimeoutMs=1136, unackedVoters=[], preferredSuccessors=[]) (org.apache.kafka.raft.Quoru
mState)
kafka-1             | [2025-01-18 17:14:41,834] INFO [RaftManager id=1] Attempting durable transition to Leader(localReplicaKey=ReplicaKey(id=1, directoryId=Optional[IjfzZ4aV_jauVtbEs6etYA]), epoch=27, epochStartOffset=62592, hi
ghWatermark=Optional.empty, voterStates={1=ReplicaState(replicaKey=ReplicaKey(id=1, directoryId=Optional.empty), endOffset=Optional.empty, lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=true)}) from Candi
dateState(localId=1, localDirectoryId=IjfzZ4aV_jauVtbEs6etYA,epoch=27, retries=1, voteStates={1=org.apache.kafka.raft.CandidateState$VoterState@37191ef0}, highWatermark=Optional.empty, electionTimeoutMs=1536) (org.apache.kafka.r
aft.QuorumState)
kafka-1             | [2025-01-18 17:14:41,849] INFO [RaftManager id=1] Completed transition to Leader(localReplicaKey=ReplicaKey(id=1, directoryId=Optional[IjfzZ4aV_jauVtbEs6etYA]), epoch=27, epochStartOffset=62592, highWaterma
rk=Optional.empty, voterStates={1=ReplicaState(replicaKey=ReplicaKey(id=1, directoryId=Optional.empty), endOffset=Optional.empty, lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=true)}) from CandidateState
(localId=1, localDirectoryId=IjfzZ4aV_jauVtbEs6etYA,epoch=27, retries=1, voteStates={1=org.apache.kafka.raft.CandidateState$VoterState@37191ef0}, highWatermark=Optional.empty, electionTimeoutMs=1536) (org.apache.kafka.raft.Quoru
mState)
kafka-1             | [2025-01-18 17:14:41,892] INFO [kafka-1-raft-outbound-request-thread]: Starting (org.apache.kafka.raft.KafkaNetworkChannel$SendThread)
kafka-1             | [2025-01-18 17:14:41,893] INFO [kafka-1-raft-io-thread]: Starting (org.apache.kafka.raft.KafkaRaftClientDriver)
calendar-sender     | [ERROR] 2025/01/18 17:14:41 Ошибка чтения сообщения:
calendar-sender     | [ERROR] 2025/01/18 17:14:41 Ошибка при получении сообщения:
kafka-1             | [2025-01-18 17:14:41,952] INFO [MetadataLoader id=1] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoad
er)
calendar-sender     | Ожидание сообщений...
kafka-1             | [2025-01-18 17:14:41,955] INFO [ControllerServer id=1] Waiting for controller quorum voters future (kafka.server.ControllerServer)
kafka-1             | [2025-01-18 17:14:41,955] INFO [ControllerServer id=1] Finished waiting for controller quorum voters future (kafka.server.ControllerServer)
kafka-1             | [2025-01-18 17:14:41,977] INFO [RaftManager id=1] High watermark set to LogOffsetMetadata(offset=62593, metadata=Optional[(segmentBaseOffset=0,relativePositionInSegment=4430700)]) for the first time for epo
ch 27 based on indexOfHw 0 and voters [ReplicaState(replicaKey=ReplicaKey(id=1, directoryId=Optional.empty), endOffset=Optional[LogOffsetMetadata(offset=62593, metadata=Optional[(segmentBaseOffset=0,relativePositionInSegment=443
0700)])], lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=true)] (org.apache.kafka.raft.LeaderState)
kafka-1             | [2025-01-18 17:14:42,016] INFO [RaftManager id=1] Registered the listener org.apache.kafka.image.loader.MetadataLoader@568250807 (org.apache.kafka.raft.KafkaRaftClient)
kafka-1             | [2025-01-18 17:14:42,022] INFO [MetadataLoader id=1] handleLoadSnapshot(00000000000000044047-0000000014): incrementing HandleLoadSnapshotCount to 1. (org.apache.kafka.image.loader.MetadataLoader)
kafka-1             | [2025-01-18 17:14:42,063] INFO [QuorumController id=1] Creating new QuorumController with clusterId HOB3vkoWQmeCauej0TOCtg. (org.apache.kafka.controller.QuorumController)
kafka-1             | [2025-01-18 17:14:42,072] INFO [RaftManager id=1] Registered the listener org.apache.kafka.controller.QuorumController$QuorumMetaLogListener@763275383 (org.apache.kafka.raft.KafkaRaftClient)
kafka-1             | [2025-01-18 17:14:42,078] INFO [MetadataLoader id=1] handleLoadSnapshot(00000000000000044047-0000000014): generated a metadata delta between offset -1 and this snapshot in 55320 us. (org.apache.kafka.image.
loader.MetadataLoader)
kafka-1             | [2025-01-18 17:14:42,080] INFO [MetadataLoader id=1] maybePublishMetadata(SNAPSHOT): The loader is still catching up because we have loaded up to offset 44046, but the high water mark is 62593 (org.apache.k
afka.image.loader.MetadataLoader)
kafka-1             | [2025-01-18 17:14:42,080] INFO [QuorumController id=1] Starting to load snapshot 00000000000000044047-0000000014. Previous lastCommittedOffset was -1. Previous transactionStartOffset was -1. (org.apache.kaf
ka.controller.OffsetControlManager)
kafka-1             | [2025-01-18 17:14:42,080] INFO [MetadataLoader id=1] initializeNewPublishers: The loader is still catching up because we have loaded up to offset 44046, but the high water mark is 62593 (org.apache.kafka.im
age.loader.MetadataLoader)
kafka-1             | [2025-01-18 17:14:42,116] INFO [QuorumController id=1] Replayed a FeatureLevelRecord setting metadata.version to 3.9-IV0 (org.apache.kafka.controller.FeatureControlManager)
kafka-1             | [2025-01-18 17:14:42,120] INFO [QuorumController id=1] Replayed initial RegisterBrokerRecord for broker 1: RegisterBrokerRecord(brokerId=1, isMigratingZkBroker=false, incarnationId=HQkW2sPkSO6nNcj-06BUUA, b
rokerEpoch=29598, endPoints=[BrokerEndpoint(name='PLAINTEXT', host='kafka', port=9092, securityProtocol=0)], features=[BrokerFeature(name='kraft.version', minSupportedVersion=0, maxSupportedVersion=1), BrokerFeature(name='metada
ta.version', minSupportedVersion=1, maxSupportedVersion=21)], rack=null, fenced=false, inControlledShutdown=false, logDirs=[IjfzZ4aV_jauVtbEs6etYA]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,122] INFO [controller-1-ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka-1             | [2025-01-18 17:14:42,127] INFO [QuorumController id=1] Replayed RegisterControllerRecord contaning ControllerRegistration(id=1, incarnationId=3dopUmR9SCaCC5KwrunEJg, zkMigrationReady=false, listeners=[Endpo
int(listenerName='CONTROLLER', securityProtocol=PLAINTEXT, host='1ffea96ab6f8', port=9093)], supportedFeatures={kraft.version: 0-1, metadata.version: 1-21}). (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,128] INFO [QuorumController id=1] Replayed TopicRecord for topic test-notifications with topic ID fBG_L4UIQeqZIcMy-eDkkw. (org.apache.kafka.controller.ReplicationControlManager)
kafka-1             | [2025-01-18 17:14:42,128] INFO [QuorumController id=1] Replayed PartitionRecord for new partition test-notifications-0 with topic ID fBG_L4UIQeqZIcMy-eDkkw and PartitionRegistration(replicas=[1], directorie
s=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlMa
nager)
kafka-1             | [2025-01-18 17:14:42,131] INFO [controller-1-ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka-1             | [2025-01-18 17:14:42,140] INFO [QuorumController id=1] Replayed TopicRecord for topic __consumer_offsets with topic ID OyIb1O_sRg6y81AbaHRyQw. (org.apache.kafka.controller.ReplicationControlManager)
kafka-1             | [2025-01-18 17:14:42,141] INFO [controller-1-ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka-1             | [2025-01-18 17:14:42,142] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-0 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directorie
s=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlMa
nager)
kafka-1             | [2025-01-18 17:14:42,144] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-1 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directorie
s=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlMa
nager)
kafka-1             | [2025-01-18 17:14:42,144] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-2 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directorie
s=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlMa
nager)
kafka-1             | [2025-01-18 17:14:42,145] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-3 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directorie
s=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlMa
nager)
kafka-1             | [2025-01-18 17:14:42,145] INFO [controller-1-ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka-1             | [2025-01-18 17:14:42,145] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-4 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directorie
s=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlMa
nager)
kafka-1             | [2025-01-18 17:14:42,146] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-5 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directorie
s=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlMa
nager)
kafka-1             | [2025-01-18 17:14:42,146] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-6 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directorie
s=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlMa
nager)
kafka-1             | [2025-01-18 17:14:42,147] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-7 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directorie
s=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlMa
nager)
kafka-1             | [2025-01-18 17:14:42,147] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-8 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directorie
s=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlMa
nager)
kafka-1             | [2025-01-18 17:14:42,147] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-9 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directorie
s=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlMa
nager)
kafka-1             | [2025-01-18 17:14:42,148] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-10 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directori
es=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlM
anager)
kafka-1             | [2025-01-18 17:14:42,148] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-11 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directori
es=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlM
anager)
kafka-1             | [2025-01-18 17:14:42,149] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-12 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directori
es=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlM
anager)
kafka-1             | [2025-01-18 17:14:42,149] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-13 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directori
es=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlM
anager)
kafka-1             | [2025-01-18 17:14:42,149] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-14 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directori
es=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlM
anager)
kafka-1             | [2025-01-18 17:14:42,150] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-15 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directori
es=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlM
anager)
kafka-1             | [2025-01-18 17:14:42,150] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-16 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directori
es=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlM
anager)
kafka-1             | [2025-01-18 17:14:42,150] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-17 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directori
es=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlM
anager)
kafka-1             | [2025-01-18 17:14:42,151] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-18 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directori
es=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlM
anager)
kafka-1             | [2025-01-18 17:14:42,151] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-19 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directori
es=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlM
anager)
kafka-1             | [2025-01-18 17:14:42,152] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-20 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directori
es=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlM
anager)
kafka-1             | [2025-01-18 17:14:42,152] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-21 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directori
es=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlM
anager)
kafka-1             | [2025-01-18 17:14:42,153] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-22 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directori
es=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlM
anager)
kafka-1             | [2025-01-18 17:14:42,153] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-23 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directori
es=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlM
anager)
kafka-1             | [2025-01-18 17:14:42,153] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-24 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directori
es=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlM
anager)
kafka-1             | [2025-01-18 17:14:42,154] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-25 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directori
es=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlM
anager)
kafka-1             | [2025-01-18 17:14:42,165] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-26 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directori
es=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlM
anager)
kafka-1             | [2025-01-18 17:14:42,165] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-27 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directori
es=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlM
anager)
kafka-1             | [2025-01-18 17:14:42,165] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-28 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directori
es=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlM
anager)
kafka-1             | [2025-01-18 17:14:42,166] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-29 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directori
es=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlM
anager)
kafka-1             | [2025-01-18 17:14:42,166] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-30 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directori
es=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlM
anager)
kafka-1             | [2025-01-18 17:14:42,166] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-31 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directori
es=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlM
anager)
kafka-1             | [2025-01-18 17:14:42,167] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-32 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directori
es=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlM
anager)
kafka-1             | [2025-01-18 17:14:42,167] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-33 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directori
es=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlM
anager)
kafka-1             | [2025-01-18 17:14:42,167] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-34 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directori
es=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlM
anager)
kafka-1             | [2025-01-18 17:14:42,167] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-35 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directori
es=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlM
anager)
kafka-1             | [2025-01-18 17:14:42,168] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-36 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directori
es=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlM
anager)
kafka-1             | [2025-01-18 17:14:42,168] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-37 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directori
es=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlM
anager)
kafka-1             | [2025-01-18 17:14:42,168] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-38 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directori
es=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlM
anager)
kafka-1             | [2025-01-18 17:14:42,169] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-39 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directori
es=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlM
anager)
kafka-1             | [2025-01-18 17:14:42,169] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-40 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directori
es=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlM
anager)
kafka-1             | [2025-01-18 17:14:42,169] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-41 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directori
es=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlM
anager)
kafka-1             | [2025-01-18 17:14:42,170] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-42 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directori
es=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlM
anager)
kafka-1             | [2025-01-18 17:14:42,170] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-43 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directori
es=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlM
anager)
kafka-1             | [2025-01-18 17:14:42,181] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-44 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directori
es=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlM
anager)
kafka-1             | [2025-01-18 17:14:42,181] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-45 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directori
es=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlM
anager)
kafka-1             | [2025-01-18 17:14:42,181] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-46 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directori
es=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlM
anager)
kafka-1             | [2025-01-18 17:14:42,182] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-47 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directori
es=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlM
anager)
kafka-1             | [2025-01-18 17:14:42,182] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-48 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directori
es=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlM
anager)
kafka-1             | [2025-01-18 17:14:42,182] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-49 with topic ID OyIb1O_sRg6y81AbaHRyQw and PartitionRegistration(replicas=[1], directori
es=[IjfzZ4aV_jauVtbEs6etYA], isr=[1], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=24, partitionEpoch=24). (org.apache.kafka.controller.ReplicationControlM
anager)
kafka-1             | [2025-01-18 17:14:42,183] INFO [QuorumController id=1] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='__consumer_offsets') which set configuration compression.type to producer (org.apache.kafka.
controller.ConfigurationControlManager)
kafka-1             | [2025-01-18 17:14:42,183] INFO [QuorumController id=1] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='__consumer_offsets') which set configuration cleanup.policy to compact (org.apache.kafka.con
troller.ConfigurationControlManager)
kafka-1             | [2025-01-18 17:14:42,183] INFO [QuorumController id=1] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='__consumer_offsets') which set configuration segment.bytes to 104857600 (org.apache.kafka.co
ntroller.ConfigurationControlManager)
kafka-1             | [2025-01-18 17:14:42,183] INFO [QuorumController id=1] Successfully loaded snapshot 00000000000000044047-0000000014. (org.apache.kafka.controller.OffsetControlManager)
kafka-1             | [2025-01-18 17:14:42,221] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka-1             | [2025-01-18 17:14:42,328] INFO [ControllerServer id=1] Waiting for the controller metadata publishers to be installed (kafka.server.ControllerServer)
kafka-1             | [2025-01-18 17:14:42,444] INFO [QuorumController id=1] Replayed RegisterControllerRecord contaning ControllerRegistration(id=1, incarnationId=NlnFe33iTMWua1iNcHvyGg, zkMigrationReady=false, listeners=[Endpo
int(listenerName='CONTROLLER', securityProtocol=PLAINTEXT, host='1ffea96ab6f8', port=9093)], supportedFeatures={kraft.version: 0-1, metadata.version: 1-21}). Previous incarnation was 3dopUmR9SCaCC5KwrunEJg (org.apache.kafka.cont
roller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,445] INFO [QuorumController id=1] Replayed RegisterBrokerRecord establishing a new incarnation of broker 1: RegisterBrokerRecord(brokerId=1, isMigratingZkBroker=false, incarnationId=PzI
YSyQFR8uVv7pFB-njYg, brokerEpoch=50953, endPoints=[BrokerEndpoint(name='PLAINTEXT', host='kafka', port=9092, securityProtocol=0)], features=[BrokerFeature(name='kraft.version', minSupportedVersion=0, maxSupportedVersion=1), Brok
erFeature(name='metadata.version', minSupportedVersion=1, maxSupportedVersion=21)], rack=null, fenced=true, inControlledShutdown=false, logDirs=[IjfzZ4aV_jauVtbEs6etYA]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,447] INFO [QuorumController id=1] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 1: BrokerRegistrationChangeRecord(brokerId=1, brokerEpoch=50953, fenced=-
1, inControlledShutdown=0, logDirs=[]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,482] INFO [QuorumController id=1] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 1: BrokerRegistrationChangeRecord(brokerId=1, brokerEpoch=50953, fenced=0
, inControlledShutdown=1, logDirs=[]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,499] INFO [QuorumController id=1] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 1: BrokerRegistrationChangeRecord(brokerId=1, brokerEpoch=50953, fenced=1
, inControlledShutdown=0, logDirs=[]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,500] INFO [QuorumController id=1] Replayed RegisterControllerRecord contaning ControllerRegistration(id=1, incarnationId=BhxHhWzWTT6crfWxcfSr0w, zkMigrationReady=false, listeners=[Endpo
int(listenerName='CONTROLLER', securityProtocol=PLAINTEXT, host='1ffea96ab6f8', port=9093)], supportedFeatures={kraft.version: 0-1, metadata.version: 1-21}). Previous incarnation was NlnFe33iTMWua1iNcHvyGg (org.apache.kafka.cont
roller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,501] INFO [QuorumController id=1] Replayed RegisterBrokerRecord establishing a new incarnation of broker 1: RegisterBrokerRecord(brokerId=1, isMigratingZkBroker=false, incarnationId=Dh-
jO_3ATWisnyC1Unukog, brokerEpoch=54593, endPoints=[BrokerEndpoint(name='PLAINTEXT', host='kafka', port=9092, securityProtocol=0)], features=[BrokerFeature(name='kraft.version', minSupportedVersion=0, maxSupportedVersion=1), Brok
erFeature(name='metadata.version', minSupportedVersion=1, maxSupportedVersion=21)], rack=null, fenced=true, inControlledShutdown=false, logDirs=[IjfzZ4aV_jauVtbEs6etYA]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,502] INFO [QuorumController id=1] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 1: BrokerRegistrationChangeRecord(brokerId=1, brokerEpoch=54593, fenced=-
1, inControlledShutdown=0, logDirs=[]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,524] INFO [QuorumController id=1] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 1: BrokerRegistrationChangeRecord(brokerId=1, brokerEpoch=54593, fenced=0
, inControlledShutdown=1, logDirs=[]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,536] INFO [QuorumController id=1] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 1: BrokerRegistrationChangeRecord(brokerId=1, brokerEpoch=54593, fenced=1
, inControlledShutdown=0, logDirs=[]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,537] INFO [QuorumController id=1] Replayed RegisterControllerRecord contaning ControllerRegistration(id=1, incarnationId=BsElyrZuQqCDSNQUHU8oBw, zkMigrationReady=false, listeners=[Endpo
int(listenerName='CONTROLLER', securityProtocol=PLAINTEXT, host='1ffea96ab6f8', port=9093)], supportedFeatures={kraft.version: 0-1, metadata.version: 1-21}). Previous incarnation was BhxHhWzWTT6crfWxcfSr0w (org.apache.kafka.cont
roller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,537] INFO [QuorumController id=1] Replayed RegisterBrokerRecord establishing a new incarnation of broker 1: RegisterBrokerRecord(brokerId=1, isMigratingZkBroker=false, incarnationId=9-G
sTx9NSnavZ82DwVQd5w, brokerEpoch=56673, endPoints=[BrokerEndpoint(name='PLAINTEXT', host='kafka', port=9092, securityProtocol=0)], features=[BrokerFeature(name='kraft.version', minSupportedVersion=0, maxSupportedVersion=1), Brok
erFeature(name='metadata.version', minSupportedVersion=1, maxSupportedVersion=21)], rack=null, fenced=true, inControlledShutdown=false, logDirs=[IjfzZ4aV_jauVtbEs6etYA]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,538] INFO [QuorumController id=1] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 1: BrokerRegistrationChangeRecord(brokerId=1, brokerEpoch=56673, fenced=-
1, inControlledShutdown=0, logDirs=[]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,544] INFO [MetadataLoader id=1] maybePublishMetadata(LOG_DELTA): The loader finished catching up to the current high water mark of 62593 (org.apache.kafka.image.loader.MetadataLoader)
kafka-1             | [2025-01-18 17:14:42,550] INFO [QuorumController id=1] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 1: BrokerRegistrationChangeRecord(brokerId=1, brokerEpoch=56673, fenced=0
, inControlledShutdown=1, logDirs=[]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,555] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing SnapshotGenerator with a snapshot at offset 62592 (org.apache.kafka.image.loader.MetadataLoader)
kafka-1             | [2025-01-18 17:14:42,556] INFO [QuorumController id=1] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 1: BrokerRegistrationChangeRecord(brokerId=1, brokerEpoch=56673, fenced=1
, inControlledShutdown=0, logDirs=[]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,557] INFO [QuorumController id=1] Replayed RegisterControllerRecord contaning ControllerRegistration(id=1, incarnationId=f_0-g5X1R-yRnh49Hds1QQ, zkMigrationReady=false, listeners=[Endpo
int(listenerName='CONTROLLER', securityProtocol=PLAINTEXT, host='1ffea96ab6f8', port=9093)], supportedFeatures={kraft.version: 0-1, metadata.version: 1-21}). Previous incarnation was BsElyrZuQqCDSNQUHU8oBw (org.apache.kafka.cont
roller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,557] INFO [ControllerServer id=1] Finished waiting for the controller metadata publishers to be installed (kafka.server.ControllerServer)
kafka-1             | [2025-01-18 17:14:42,558] INFO [QuorumController id=1] Replayed RegisterBrokerRecord establishing a new incarnation of broker 1: RegisterBrokerRecord(brokerId=1, isMigratingZkBroker=false, incarnationId=ZHb
GwQnBRvO_4SjbAqdTZQ, brokerEpoch=56864, endPoints=[BrokerEndpoint(name='PLAINTEXT', host='kafka', port=9092, securityProtocol=0)], features=[BrokerFeature(name='kraft.version', minSupportedVersion=0, maxSupportedVersion=1), Brok
erFeature(name='metadata.version', minSupportedVersion=1, maxSupportedVersion=21)], rack=null, fenced=true, inControlledShutdown=false, logDirs=[IjfzZ4aV_jauVtbEs6etYA]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,558] INFO [QuorumController id=1] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 1: BrokerRegistrationChangeRecord(brokerId=1, brokerEpoch=56864, fenced=-
1, inControlledShutdown=0, logDirs=[]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,559] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing KRaftMetadataCachePublisher with a snapshot at offset 62592 (org.apache.kafka.image.loader.MetadataLoader)
kafka-1             | [2025-01-18 17:14:42,560] INFO [SocketServer listenerType=CONTROLLER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
kafka-1             | [2025-01-18 17:14:42,566] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing FeaturesPublisher with a snapshot at offset 62592 (org.apache.kafka.image.loader.MetadataLoader)
kafka-1             | [2025-01-18 17:14:42,567] INFO [ControllerServer id=1] Loaded new metadata Features(metadataVersion=3.9-IV0, finalizedFeatures={metadata.version=21}, finalizedFeaturesEpoch=62592). (org.apache.kafka.metadat
a.publisher.FeaturesPublisher)
kafka-1             | [2025-01-18 17:14:42,567] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ControllerRegistrationsPublisher with a snapshot at offset 62592 (org.apache.kafka.image.loader.MetadataLoader)
kafka-1             | [2025-01-18 17:14:42,568] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ControllerRegistrationManager with a snapshot at offset 62592 (org.apache.kafka.image.loader.MetadataLoader)
kafka-1             | [2025-01-18 17:14:42,570] INFO [ControllerRegistrationManager id=1 incarnation=_IrIs8iUSGuYY7c0b-saqg] Found registration for pbJihCI2QaCbhnnsFWF_CA instead of our incarnation. (kafka.server.ControllerRegis
trationManager)
kafka-1             | [2025-01-18 17:14:42,572] INFO [QuorumController id=1] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 1: BrokerRegistrationChangeRecord(brokerId=1, brokerEpoch=56864, fenced=0
, inControlledShutdown=1, logDirs=[]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,576] INFO [QuorumController id=1] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 1: BrokerRegistrationChangeRecord(brokerId=1, brokerEpoch=56864, fenced=1
, inControlledShutdown=0, logDirs=[]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,577] INFO [QuorumController id=1] Replayed RegisterControllerRecord contaning ControllerRegistration(id=1, incarnationId=WujSgYtiQ8GQbNd1bnt08A, zkMigrationReady=false, listeners=[Endpo
int(listenerName='CONTROLLER', securityProtocol=PLAINTEXT, host='fe335a92a3e6', port=9093)], supportedFeatures={kraft.version: 0-1, metadata.version: 1-21}). Previous incarnation was f_0-g5X1R-yRnh49Hds1QQ (org.apache.kafka.cont
roller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,577] INFO [QuorumController id=1] Replayed RegisterBrokerRecord establishing a new incarnation of broker 1: RegisterBrokerRecord(brokerId=1, isMigratingZkBroker=false, incarnationId=ZHI
9kK4QQA6W2oOEtxuLYQ, brokerEpoch=57055, endPoints=[BrokerEndpoint(name='PLAINTEXT', host='kafka', port=9092, securityProtocol=0)], features=[BrokerFeature(name='kraft.version', minSupportedVersion=0, maxSupportedVersion=1), Brok
erFeature(name='metadata.version', minSupportedVersion=1, maxSupportedVersion=21)], rack=null, fenced=true, inControlledShutdown=false, logDirs=[IjfzZ4aV_jauVtbEs6etYA]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,578] INFO [QuorumController id=1] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 1: BrokerRegistrationChangeRecord(brokerId=1, brokerEpoch=57055, fenced=-
1, inControlledShutdown=0, logDirs=[]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,578] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.DataPlaneAcceptor)
kafka-1             | [2025-01-18 17:14:42,580] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing DynamicConfigPublisher controller id=1 with a snapshot at offset 62592 (org.apache.kafka.image.loader.MetadataLoade
r)
kafka-1             | [2025-01-18 17:14:42,583] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing DynamicClientQuotaPublisher controller id=1 with a snapshot at offset 62592 (org.apache.kafka.image.loader.Metadata
Loader)
kafka-1             | [2025-01-18 17:14:42,589] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ScramPublisher controller id=1 with a snapshot at offset 62592 (org.apache.kafka.image.loader.MetadataLoader)
kafka-1             | [2025-01-18 17:14:42,598] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing DelegationTokenPublisher controller id=1 with a snapshot at offset 62592 (org.apache.kafka.image.loader.MetadataLoa
der)
kafka-1             | [2025-01-18 17:14:42,601] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ControllerMetadataMetricsPublisher with a snapshot at offset 62592 (org.apache.kafka.image.loader.MetadataLoader)
kafka-1             | [2025-01-18 17:14:42,602] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing AclPublisher controller id=1 with a snapshot at offset 62592 (org.apache.kafka.image.loader.MetadataLoader)
kafka-1             | [2025-01-18 17:14:42,603] INFO [QuorumController id=1] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 1: BrokerRegistrationChangeRecord(brokerId=1, brokerEpoch=57055, fenced=0
, inControlledShutdown=1, logDirs=[]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,609] INFO [QuorumController id=1] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 1: BrokerRegistrationChangeRecord(brokerId=1, brokerEpoch=57055, fenced=1
, inControlledShutdown=0, logDirs=[]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,609] INFO [QuorumController id=1] Replayed RegisterControllerRecord contaning ControllerRegistration(id=1, incarnationId=jSUx5QCMRgGJlMY_Y31NvQ, zkMigrationReady=false, listeners=[Endpo
int(listenerName='CONTROLLER', securityProtocol=PLAINTEXT, host='7149655950ad', port=9093)], supportedFeatures={kraft.version: 0-1, metadata.version: 1-21}). Previous incarnation was WujSgYtiQ8GQbNd1bnt08A (org.apache.kafka.cont
roller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,610] INFO [QuorumController id=1] Replayed RegisterBrokerRecord establishing a new incarnation of broker 1: RegisterBrokerRecord(brokerId=1, isMigratingZkBroker=false, incarnationId=M92
0voszRAKarMLaEy-3eg, brokerEpoch=58012, endPoints=[BrokerEndpoint(name='PLAINTEXT', host='kafka', port=9092, securityProtocol=0)], features=[BrokerFeature(name='kraft.version', minSupportedVersion=0, maxSupportedVersion=1), Brok
erFeature(name='metadata.version', minSupportedVersion=1, maxSupportedVersion=21)], rack=null, fenced=true, inControlledShutdown=false, logDirs=[IjfzZ4aV_jauVtbEs6etYA]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,611] INFO [QuorumController id=1] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 1: BrokerRegistrationChangeRecord(brokerId=1, brokerEpoch=58012, fenced=-
1, inControlledShutdown=0, logDirs=[]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,614] INFO [QuorumController id=1] Replayed RegisterControllerRecord contaning ControllerRegistration(id=1, incarnationId=IQcTHWRQTfuOsWMEIaAFsw, zkMigrationReady=false, listeners=[Endpo
int(listenerName='CONTROLLER', securityProtocol=PLAINTEXT, host='c6f5f28da69e', port=9093)], supportedFeatures={kraft.version: 0-1, metadata.version: 1-21}). Previous incarnation was jSUx5QCMRgGJlMY_Y31NvQ (org.apache.kafka.cont
roller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,615] INFO [QuorumController id=1] Replayed RegisterBrokerRecord establishing a new incarnation of broker 1: RegisterBrokerRecord(brokerId=1, isMigratingZkBroker=false, incarnationId=2rv
9ZQ7dTOCYvmVw6PZ0jw, brokerEpoch=58201, endPoints=[BrokerEndpoint(name='PLAINTEXT', host='kafka', port=9092, securityProtocol=0)], features=[BrokerFeature(name='kraft.version', minSupportedVersion=0, maxSupportedVersion=1), Brok
erFeature(name='metadata.version', minSupportedVersion=1, maxSupportedVersion=21)], rack=null, fenced=true, inControlledShutdown=false, logDirs=[IjfzZ4aV_jauVtbEs6etYA]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,615] INFO [QuorumController id=1] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 1: BrokerRegistrationChangeRecord(brokerId=1, brokerEpoch=58201, fenced=-
1, inControlledShutdown=0, logDirs=[]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,645] INFO [QuorumController id=1] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 1: BrokerRegistrationChangeRecord(brokerId=1, brokerEpoch=58201, fenced=0
, inControlledShutdown=1, logDirs=[]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,648] INFO [QuorumController id=1] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 1: BrokerRegistrationChangeRecord(brokerId=1, brokerEpoch=58201, fenced=1
, inControlledShutdown=0, logDirs=[]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,649] INFO [QuorumController id=1] Replayed RegisterControllerRecord contaning ControllerRegistration(id=1, incarnationId=_kZAgz_fQsqgxkZdeYkBPQ, zkMigrationReady=false, listeners=[Endpo
int(listenerName='CONTROLLER', securityProtocol=PLAINTEXT, host='541f6c7baf64', port=9093)], supportedFeatures={kraft.version: 0-1, metadata.version: 1-21}). Previous incarnation was IQcTHWRQTfuOsWMEIaAFsw (org.apache.kafka.cont
roller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,649] INFO [QuorumController id=1] Replayed RegisterBrokerRecord establishing a new incarnation of broker 1: RegisterBrokerRecord(brokerId=1, isMigratingZkBroker=false, incarnationId=oWW
iUDDiRCSkvI3SY_pSdQ, brokerEpoch=58853, endPoints=[BrokerEndpoint(name='PLAINTEXT', host='kafka', port=9092, securityProtocol=0)], features=[BrokerFeature(name='kraft.version', minSupportedVersion=0, maxSupportedVersion=1), Brok
erFeature(name='metadata.version', minSupportedVersion=1, maxSupportedVersion=21)], rack=null, fenced=true, inControlledShutdown=false, logDirs=[IjfzZ4aV_jauVtbEs6etYA]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,650] INFO [QuorumController id=1] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 1: BrokerRegistrationChangeRecord(brokerId=1, brokerEpoch=58853, fenced=-
1, inControlledShutdown=0, logDirs=[]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,668] INFO [QuorumController id=1] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 1: BrokerRegistrationChangeRecord(brokerId=1, brokerEpoch=58853, fenced=0
, inControlledShutdown=1, logDirs=[]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,673] INFO [QuorumController id=1] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 1: BrokerRegistrationChangeRecord(brokerId=1, brokerEpoch=58853, fenced=1
, inControlledShutdown=0, logDirs=[]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,675] INFO [QuorumController id=1] Replayed RegisterControllerRecord contaning ControllerRegistration(id=1, incarnationId=nSVzms9wSsi6RyOZgUf0iA, zkMigrationReady=false, listeners=[Endpo
int(listenerName='CONTROLLER', securityProtocol=PLAINTEXT, host='541f6c7baf64', port=9093)], supportedFeatures={kraft.version: 0-1, metadata.version: 1-21}). Previous incarnation was _kZAgz_fQsqgxkZdeYkBPQ (org.apache.kafka.cont
roller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,677] INFO [QuorumController id=1] Replayed RegisterBrokerRecord establishing a new incarnation of broker 1: RegisterBrokerRecord(brokerId=1, isMigratingZkBroker=false, incarnationId=5fw
zNFWgTcyZWT-NYrpgoQ, brokerEpoch=61422, endPoints=[BrokerEndpoint(name='PLAINTEXT', host='kafka', port=9092, securityProtocol=0)], features=[BrokerFeature(name='kraft.version', minSupportedVersion=0, maxSupportedVersion=1), Brok
erFeature(name='metadata.version', minSupportedVersion=1, maxSupportedVersion=21)], rack=null, fenced=true, inControlledShutdown=false, logDirs=[IjfzZ4aV_jauVtbEs6etYA]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,679] INFO [QuorumController id=1] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 1: BrokerRegistrationChangeRecord(brokerId=1, brokerEpoch=61422, fenced=-
1, inControlledShutdown=0, logDirs=[]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,686] INFO [QuorumController id=1] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 1: BrokerRegistrationChangeRecord(brokerId=1, brokerEpoch=61422, fenced=0
, inControlledShutdown=1, logDirs=[]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,688] INFO [QuorumController id=1] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 1: BrokerRegistrationChangeRecord(brokerId=1, brokerEpoch=61422, fenced=1
, inControlledShutdown=0, logDirs=[]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,689] INFO [QuorumController id=1] Replayed RegisterControllerRecord contaning ControllerRegistration(id=1, incarnationId=UGdXH3nQSGWtfnvV7pEUaQ, zkMigrationReady=false, listeners=[Endpo
int(listenerName='CONTROLLER', securityProtocol=PLAINTEXT, host='541f6c7baf64', port=9093)], supportedFeatures={kraft.version: 0-1, metadata.version: 1-21}). Previous incarnation was nSVzms9wSsi6RyOZgUf0iA (org.apache.kafka.cont
roller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,689] INFO [QuorumController id=1] Replayed RegisterBrokerRecord establishing a new incarnation of broker 1: RegisterBrokerRecord(brokerId=1, isMigratingZkBroker=false, incarnationId=yyD
U2iLlQKSGL5-xUIvbLA, brokerEpoch=61677, endPoints=[BrokerEndpoint(name='PLAINTEXT', host='kafka', port=9092, securityProtocol=0)], features=[BrokerFeature(name='kraft.version', minSupportedVersion=0, maxSupportedVersion=1), Brok
erFeature(name='metadata.version', minSupportedVersion=1, maxSupportedVersion=21)], rack=null, fenced=true, inControlledShutdown=false, logDirs=[IjfzZ4aV_jauVtbEs6etYA]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,690] INFO [QuorumController id=1] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 1: BrokerRegistrationChangeRecord(brokerId=1, brokerEpoch=61677, fenced=-
1, inControlledShutdown=0, logDirs=[]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,693] INFO [QuorumController id=1] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 1: BrokerRegistrationChangeRecord(brokerId=1, brokerEpoch=61677, fenced=0
, inControlledShutdown=1, logDirs=[]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,696] INFO [QuorumController id=1] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 1: BrokerRegistrationChangeRecord(brokerId=1, brokerEpoch=61677, fenced=1
, inControlledShutdown=0, logDirs=[]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,697] INFO [QuorumController id=1] Replayed RegisterControllerRecord contaning ControllerRegistration(id=1, incarnationId=1Vow0m_1RKuJNzOo7O_OQw, zkMigrationReady=false, listeners=[Endpo
int(listenerName='CONTROLLER', securityProtocol=PLAINTEXT, host='eb5434ea967b', port=9093)], supportedFeatures={kraft.version: 0-1, metadata.version: 1-21}). Previous incarnation was UGdXH3nQSGWtfnvV7pEUaQ (org.apache.kafka.cont
roller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,698] INFO [QuorumController id=1] Replayed RegisterBrokerRecord establishing a new incarnation of broker 1: RegisterBrokerRecord(brokerId=1, isMigratingZkBroker=false, incarnationId=GdT
kldydQ8yy8_aJ-mBvFw, brokerEpoch=61822, endPoints=[BrokerEndpoint(name='PLAINTEXT', host='kafka', port=9092, securityProtocol=0)], features=[BrokerFeature(name='kraft.version', minSupportedVersion=0, maxSupportedVersion=1), Brok
erFeature(name='metadata.version', minSupportedVersion=1, maxSupportedVersion=21)], rack=null, fenced=true, inControlledShutdown=false, logDirs=[IjfzZ4aV_jauVtbEs6etYA]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,699] INFO [QuorumController id=1] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 1: BrokerRegistrationChangeRecord(brokerId=1, brokerEpoch=61822, fenced=-
1, inControlledShutdown=0, logDirs=[]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,703] INFO [ControllerRegistrationManager id=1 incarnation=_IrIs8iUSGuYY7c0b-saqg] initialized channel manager. (kafka.server.ControllerRegistrationManager)
kafka-1             | [2025-01-18 17:14:42,705] INFO [controller-1-to-controller-registration-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
kafka-1             | [2025-01-18 17:14:42,705] INFO [QuorumController id=1] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 1: BrokerRegistrationChangeRecord(brokerId=1, brokerEpoch=61822, fenced=0
, inControlledShutdown=1, logDirs=[]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,708] INFO [QuorumController id=1] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 1: BrokerRegistrationChangeRecord(brokerId=1, brokerEpoch=61822, fenced=1
, inControlledShutdown=0, logDirs=[]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,708] INFO [QuorumController id=1] Replayed RegisterControllerRecord contaning ControllerRegistration(id=1, incarnationId=pbJihCI2QaCbhnnsFWF_CA, zkMigrationReady=false, listeners=[Endpo
int(listenerName='CONTROLLER', securityProtocol=PLAINTEXT, host='eb5434ea967b', port=9093)], supportedFeatures={kraft.version: 0-1, metadata.version: 1-21}). Previous incarnation was 1Vow0m_1RKuJNzOo7O_OQw (org.apache.kafka.cont
roller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,709] INFO [QuorumController id=1] Replayed RegisterBrokerRecord establishing a new incarnation of broker 1: RegisterBrokerRecord(brokerId=1, isMigratingZkBroker=false, incarnationId=XNY
6-hGxSiyuqKv_050cYw, brokerEpoch=62265, endPoints=[BrokerEndpoint(name='PLAINTEXT', host='kafka', port=9092, securityProtocol=0)], features=[BrokerFeature(name='kraft.version', minSupportedVersion=0, maxSupportedVersion=1), Brok
erFeature(name='metadata.version', minSupportedVersion=1, maxSupportedVersion=21)], rack=null, fenced=true, inControlledShutdown=false, logDirs=[IjfzZ4aV_jauVtbEs6etYA]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,709] INFO [QuorumController id=1] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 1: BrokerRegistrationChangeRecord(brokerId=1, brokerEpoch=62265, fenced=-
1, inControlledShutdown=0, logDirs=[]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,711] INFO [controller-1-to-controller-registration-channel-manager]: Recorded new KRaft controller, from now on will use node 127.0.0.1:9093 (id: 1 rack: null) (kafka.server.NodeToContr
ollerRequestThread)
kafka-1             | [2025-01-18 17:14:42,714] INFO [ControllerRegistrationManager id=1 incarnation=_IrIs8iUSGuYY7c0b-saqg] sendControllerRegistration: attempting to send ControllerRegistrationRequestData(controllerId=1, incarn
ationId=_IrIs8iUSGuYY7c0b-saqg, zkMigrationReady=false, listeners=[Listener(name='CONTROLLER', host='eb5434ea967b', port=9093, securityProtocol=0)], features=[Feature(name='kraft.version', minSupportedVersion=0, maxSupportedVers
ion=1), Feature(name='metadata.version', minSupportedVersion=1, maxSupportedVersion=21)]) (kafka.server.ControllerRegistrationManager)
kafka-1             | [2025-01-18 17:14:42,718] INFO [ControllerServer id=1] Waiting for all of the authorizer futures to be completed (kafka.server.ControllerServer)
kafka-1             | [2025-01-18 17:14:42,718] INFO [ControllerServer id=1] Finished waiting for all of the authorizer futures to be completed (kafka.server.ControllerServer)
kafka-1             | [2025-01-18 17:14:42,718] INFO [ControllerServer id=1] Waiting for all of the SocketServer Acceptors to be started (kafka.server.ControllerServer)
kafka-1             | [2025-01-18 17:14:42,718] INFO [ControllerServer id=1] Finished waiting for all of the SocketServer Acceptors to be started (kafka.server.ControllerServer)
kafka-1             | [2025-01-18 17:14:42,719] INFO [BrokerServer id=1] Transition from SHUTDOWN to STARTING (kafka.server.BrokerServer)
kafka-1             | [2025-01-18 17:14:42,721] INFO [BrokerServer id=1] Starting broker (kafka.server.BrokerServer)
kafka-1             | [2025-01-18 17:14:42,721] INFO [QuorumController id=1] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 1: BrokerRegistrationChangeRecord(brokerId=1, brokerEpoch=62265, fenced=0
, inControlledShutdown=1, logDirs=[]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,723] INFO [QuorumController id=1] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 1: BrokerRegistrationChangeRecord(brokerId=1, brokerEpoch=62265, fenced=1
, inControlledShutdown=0, logDirs=[]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:42,731] INFO [QuorumController id=1] Becoming the active controller at epoch 27, next write offset 62593. (org.apache.kafka.controller.QuorumController)
kafka-1             | [2025-01-18 17:14:42,740] WARN [QuorumController id=1] Performing controller activation. Loaded ZK migration state of NONE. This is expected because this is a de-novo KRaft cluster. (org.apache.kafka.contro
ller.QuorumController)
kafka-1             | [2025-01-18 17:14:42,757] INFO [broker-1-ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka-1             | [2025-01-18 17:14:42,757] INFO [broker-1-ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka-1             | [2025-01-18 17:14:42,771] INFO [broker-1-ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka-1             | [2025-01-18 17:14:42,772] INFO [broker-1-ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka-1             | [2025-01-18 17:14:42,940] INFO [BrokerServer id=1] Waiting for controller quorum voters future (kafka.server.BrokerServer)
kafka-1             | [2025-01-18 17:14:42,940] INFO [BrokerServer id=1] Finished waiting for controller quorum voters future (kafka.server.BrokerServer)
kafka-1             | [2025-01-18 17:14:42,955] INFO [broker-1-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
kafka-1             | [2025-01-18 17:14:42,956] INFO [broker-1-to-controller-forwarding-channel-manager]: Recorded new KRaft controller, from now on will use node 127.0.0.1:9093 (id: 1 rack: null) (kafka.server.NodeToControllerR
equestThread)
kafka-1             | [2025-01-18 17:14:43,002] INFO [client-metrics-reaper]: Starting (org.apache.kafka.server.util.timer.SystemTimerReaper$Reaper)
kafka-1             | [2025-01-18 17:14:43,050] INFO [QuorumController id=1] Replayed RegisterControllerRecord contaning ControllerRegistration(id=1, incarnationId=_IrIs8iUSGuYY7c0b-saqg, zkMigrationReady=false, listeners=[Endpo
int(listenerName='CONTROLLER', securityProtocol=PLAINTEXT, host='eb5434ea967b', port=9093)], supportedFeatures={kraft.version: 0-1, metadata.version: 1-21}). Previous incarnation was pbJihCI2QaCbhnnsFWF_CA (org.apache.kafka.cont
roller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:43,098] INFO [ControllerRegistrationManager id=1 incarnation=_IrIs8iUSGuYY7c0b-saqg] Our registration has been persisted to the metadata log. (kafka.server.ControllerRegistrationManager)
kafka-1             | [2025-01-18 17:14:43,128] INFO [ControllerRegistrationManager id=1 incarnation=_IrIs8iUSGuYY7c0b-saqg] RegistrationResponseHandler: controller acknowledged ControllerRegistrationRequest. (kafka.server.Contr
ollerRegistrationManager)
kafka-1             | [2025-01-18 17:14:43,210] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
kafka-1             | [2025-01-18 17:14:43,222] INFO [SocketServer listenerType=BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
kafka-1             | [2025-01-18 17:14:43,237] INFO [broker-1-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
kafka-1             | [2025-01-18 17:14:43,237] INFO [broker-1-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node 127.0.0.1:9093 (id: 1 rack: null) (kafka.server.NodeToContro
llerRequestThread)
kafka-1             | [2025-01-18 17:14:43,296] INFO [broker-1-to-controller-directory-assignments-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
kafka-1             | [2025-01-18 17:14:43,297] INFO [broker-1-to-controller-directory-assignments-channel-manager]: Recorded new KRaft controller, from now on will use node 127.0.0.1:9093 (id: 1 rack: null) (kafka.server.NodeTo
ControllerRequestThread)
kafka-1             | [2025-01-18 17:14:43,330] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka-1             | [2025-01-18 17:14:43,333] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka-1             | [2025-01-18 17:14:43,355] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka-1             | [2025-01-18 17:14:43,358] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka-1             | [2025-01-18 17:14:43,361] INFO [ExpirationReaper-1-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka-1             | [2025-01-18 17:14:43,449] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka-1             | [2025-01-18 17:14:43,456] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka-1             | [2025-01-18 17:14:43,725] INFO [broker-1-to-controller-heartbeat-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
kafka-1             | [2025-01-18 17:14:43,725] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node 127.0.0.1:9093 (id: 1 rack: null) (kafka.server.NodeToControllerRe
questThread)
kafka-1             | [2025-01-18 17:14:43,733] INFO [BrokerLifecycleManager id=1] Incarnation SOk0g9lHR42M5zeMobuUlQ of broker 1 in cluster HOB3vkoWQmeCauej0TOCtg is now STARTING. (kafka.server.BrokerLifecycleManager)
kafka-1             | [2025-01-18 17:14:43,756] INFO [QuorumController id=1] Registering a new incarnation of broker 1. Previous incarnation ID was XNY6-hGxSiyuqKv_050cYw; new incarnation ID is SOk0g9lHR42M5zeMobuUlQ. Generated
0 record(s) to clean up previous incarnations. Broker epoch will become 62596. (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:43,760] INFO [QuorumController id=1] Replayed RegisterBrokerRecord establishing a new incarnation of broker 1: RegisterBrokerRecord(brokerId=1, isMigratingZkBroker=false, incarnationId=SOk
0g9lHR42M5zeMobuUlQ, brokerEpoch=62596, endPoints=[BrokerEndpoint(name='PLAINTEXT', host='kafka', port=9092, securityProtocol=0)], features=[BrokerFeature(name='kraft.version', minSupportedVersion=0, maxSupportedVersion=1), Brok
erFeature(name='metadata.version', minSupportedVersion=1, maxSupportedVersion=21)], rack=null, fenced=true, inControlledShutdown=false, logDirs=[IjfzZ4aV_jauVtbEs6etYA]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:43,769] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka-1             | [2025-01-18 17:14:43,780] INFO [BrokerLifecycleManager id=1] Successfully registered broker 1 with broker epoch 62596 (kafka.server.BrokerLifecycleManager)
kafka-1             | [2025-01-18 17:14:43,810] INFO [BrokerLifecycleManager id=1] The broker has caught up. Transitioning from STARTING to RECOVERY. (kafka.server.BrokerLifecycleManager)
kafka-1             | [2025-01-18 17:14:43,824] INFO [BrokerServer id=1] Waiting for the broker metadata publishers to be installed (kafka.server.BrokerServer)
kafka-1             | [2025-01-18 17:14:43,824] INFO [BrokerServer id=1] Finished waiting for the broker metadata publishers to be installed (kafka.server.BrokerServer)
kafka-1             | [2025-01-18 17:14:43,825] INFO [BrokerServer id=1] Waiting for the controller to acknowledge that we are caught up (kafka.server.BrokerServer)
kafka-1             | [2025-01-18 17:14:43,825] INFO [BrokerServer id=1] Finished waiting for the controller to acknowledge that we are caught up (kafka.server.BrokerServer)
kafka-1             | [2025-01-18 17:14:43,826] INFO [BrokerServer id=1] Waiting for the initial broker metadata update to be published (kafka.server.BrokerServer)
kafka-1             | [2025-01-18 17:14:43,828] INFO [BrokerLifecycleManager id=1] The broker is in RECOVERY. (kafka.server.BrokerLifecycleManager)
kafka-1             | [2025-01-18 17:14:43,830] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing MetadataVersionPublisher(id=1) with a snapshot at offset 62596 (org.apache.kafka.image.loader.MetadataLoader)
kafka-1             | [2025-01-18 17:14:43,831] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing BrokerMetadataPublisher with a snapshot at offset 62596 (org.apache.kafka.image.loader.MetadataLoader)
calendar-scheduler exited with code 1
kafka-1             | [2025-01-18 17:14:43,832] INFO [BrokerMetadataPublisher id=1] Publishing initial metadata at offset OffsetAndEpoch(offset=62596, epoch=27) with metadata.version 3.9-IV0. (kafka.server.metadata.BrokerMetadat
aPublisher)
kafka-1             | [2025-01-18 17:14:43,853] INFO Loading logs from log dirs ArrayBuffer(/bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:43,881] INFO Skipping recovery of 51 logs from /bitnami/kafka/data since clean shutdown file was found (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:43,918] INFO [LogLoader partition=test-notifications-0, dir=/bitnami/kafka/data] Loading producer state till offset 20 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:43,918] INFO [LogLoader partition=test-notifications-0, dir=/bitnami/kafka/data] Reloading from producer snapshot and rebuilding producer state from offset 20 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:43,919] INFO [ProducerStateManager partition=test-notifications-0] Loading producer state from snapshot file 'SnapshotFile(offset=20, file=/bitnami/kafka/data/test-notifications-0/00000000
000000000020.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
kafka-1             | [2025-01-18 17:14:43,921] INFO [LogLoader partition=test-notifications-0, dir=/bitnami/kafka/data] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 20 (kafka.log.U
nifiedLog$)
kafka-1             | [2025-01-18 17:14:43,958] INFO Completed load of Log(dir=/bitnami/kafka/data/test-notifications-0, topicId=fBG_L4UIQeqZIcMy-eDkkw, topic=test-notifications, partition=0, highWatermark=0, lastStableOffset=0,
 logStartOffset=0, logEndOffset=20) with 1 segments, local-log-start-offset 0 and log-end-offset 20 in 34ms (1/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:43,978] INFO [LogLoader partition=__consumer_offsets-10, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,001] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-10, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=
0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 43ms (2/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:44,035] INFO [LogLoader partition=__consumer_offsets-26, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,041] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-26, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=
0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 39ms (3/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:44,067] INFO [LogLoader partition=__consumer_offsets-22, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,070] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-22, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=
0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 29ms (4/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:44,102] INFO [LogLoader partition=__consumer_offsets-38, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,104] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-38, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=
0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 33ms (5/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:44,113] INFO [LogLoader partition=__consumer_offsets-39, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,119] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-39, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=
0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 14ms (6/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:44,135] INFO [LogLoader partition=__consumer_offsets-42, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,137] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-42, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=
0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 17ms (7/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:44,178] INFO [LogLoader partition=__consumer_offsets-9, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,180] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-9, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0,
 logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 40ms (8/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:44,197] INFO [LogLoader partition=__consumer_offsets-13, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,199] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-13, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=
0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 19ms (9/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:44,214] INFO [LogLoader partition=__consumer_offsets-27, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,217] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-27, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=
0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 17ms (10/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:44,234] INFO [LogLoader partition=__consumer_offsets-19, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,236] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-19, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=
0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 9ms (11/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:44,270] INFO Deleted producer state snapshot /bitnami/kafka/data/__consumer_offsets-43/00000000000000000039.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
kafka-1             | [2025-01-18 17:14:44,278] INFO [LogLoader partition=__consumer_offsets-43, dir=/bitnami/kafka/data] Loading producer state till offset 40 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,280] INFO [LogLoader partition=__consumer_offsets-43, dir=/bitnami/kafka/data] Reloading from producer snapshot and rebuilding producer state from offset 40 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,281] INFO [ProducerStateManager partition=__consumer_offsets-43] Loading producer state from snapshot file 'SnapshotFile(offset=40, file=/bitnami/kafka/data/__consumer_offsets-43/000000
00000000000040.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
kafka-1             | [2025-01-18 17:14:44,281] INFO [LogLoader partition=__consumer_offsets-43, dir=/bitnami/kafka/data] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 40 (kafka.log.
UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,283] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-43, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=
0, logStartOffset=0, logEndOffset=40) with 1 segments, local-log-start-offset 0 and log-end-offset 40 in 47ms (12/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:44,292] INFO [LogLoader partition=__consumer_offsets-24, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,299] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-24, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=
0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 15ms (13/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:44,325] INFO [LogLoader partition=__consumer_offsets-32, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,327] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-32, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=
0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 27ms (14/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:44,338] INFO [LogLoader partition=__consumer_offsets-34, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,340] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-34, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=
0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 13ms (15/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:44,345] INFO [LogLoader partition=__consumer_offsets-28, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,347] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-28, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=
0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (16/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:44,363] INFO [LogLoader partition=__consumer_offsets-7, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,366] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-7, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0,
 logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 19ms (17/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:44,379] INFO [LogLoader partition=__consumer_offsets-17, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,382] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-17, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=
0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 16ms (18/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:44,394] INFO [LogLoader partition=__consumer_offsets-31, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,400] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-31, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=
0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 17ms (19/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:44,433] INFO [LogLoader partition=__consumer_offsets-37, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,436] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-37, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=
0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 35ms (20/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:44,444] INFO [LogLoader partition=__consumer_offsets-44, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,446] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-44, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=
0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 8ms (21/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:44,456] INFO [LogLoader partition=__consumer_offsets-4, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,459] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-4, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0,
 logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 12ms (22/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:44,466] INFO [LogLoader partition=__consumer_offsets-11, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,478] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-11, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=
0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 19ms (23/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:44,486] INFO [LogLoader partition=__consumer_offsets-35, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,489] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-35, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=
0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 9ms (24/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:44,496] INFO [LogLoader partition=__consumer_offsets-21, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,498] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-21, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=
0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 8ms (25/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:44,512] INFO [LogLoader partition=__consumer_offsets-1, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,514] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-1, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0,
 logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 16ms (26/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:44,527] INFO [LogLoader partition=__consumer_offsets-36, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,530] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-36, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=
0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 15ms (27/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:44,548] INFO [LogLoader partition=__consumer_offsets-8, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,550] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-8, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0,
 logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 19ms (28/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:44,595] INFO [LogLoader partition=__consumer_offsets-3, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,597] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-3, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0,
 logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 47ms (29/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:44,607] INFO [LogLoader partition=__consumer_offsets-2, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,615] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-2, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0,
 logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 17ms (30/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:44,621] INFO [LogLoader partition=__consumer_offsets-16, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,627] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-16, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=
0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 12ms (31/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:44,637] INFO [LogLoader partition=__consumer_offsets-41, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,640] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-41, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=
0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 12ms (32/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:44,680] INFO [LogLoader partition=__consumer_offsets-29, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,682] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-29, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=
0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 40ms (33/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:44,693] INFO [LogLoader partition=__consumer_offsets-5, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,709] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-5, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0,
 logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 27ms (34/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:44,714] INFO [LogLoader partition=__consumer_offsets-30, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,728] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-30, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=
0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 19ms (35/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:44,761] INFO [LogLoader partition=__consumer_offsets-25, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,765] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-25, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=
0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 35ms (36/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:44,770] INFO [LogLoader partition=__consumer_offsets-6, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,782] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-6, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0,
 logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 17ms (37/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:44,837] INFO [LogLoader partition=__consumer_offsets-47, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,839] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-47, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=
0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 56ms (38/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:44,851] INFO [LogLoader partition=__consumer_offsets-14, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,861] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-14, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=
0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 22ms (39/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:44,868] INFO [LogLoader partition=__consumer_offsets-23, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,871] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-23, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=
0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (40/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:44,893] INFO [LogLoader partition=__consumer_offsets-48, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,896] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-48, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=
0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 25ms (41/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:44,900] INFO [LogLoader partition=__consumer_offsets-40, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,903] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-40, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=
0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (42/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:44,921] INFO [LogLoader partition=__consumer_offsets-12, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,924] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-12, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=
0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 21ms (43/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:44,938] INFO [LogLoader partition=__consumer_offsets-0, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,940] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-0, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0,
 logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 16ms (44/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:44,965] INFO [LogLoader partition=__consumer_offsets-45, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,967] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-45, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=
0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 27ms (45/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:44,972] INFO [LogLoader partition=__consumer_offsets-49, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,974] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-49, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=
0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (46/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:44,985] INFO [LogLoader partition=__consumer_offsets-20, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:44,987] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-20, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=
0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 13ms (47/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:45,000] INFO [LogLoader partition=__consumer_offsets-15, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:45,007] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-15, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=
0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 19ms (48/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:45,014] INFO [LogLoader partition=__consumer_offsets-33, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:45,016] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-33, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=
0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 9ms (49/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:45,026] INFO [LogLoader partition=__consumer_offsets-46, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:45,027] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-46, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=
0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 11ms (50/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:45,040] INFO [LogLoader partition=__consumer_offsets-18, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka-1             | [2025-01-18 17:14:45,046] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-18, topicId=OyIb1O_sRg6y81AbaHRyQw, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=
0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 18ms (51/51 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:45,056] INFO Loaded 51 logs in 1200ms (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:45,057] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:45,061] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
kafka-1             | [2025-01-18 17:14:45,103] INFO Starting the log cleaner (kafka.log.LogCleaner)
kafka-1             | [2025-01-18 17:14:45,208] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
kafka-1             | [2025-01-18 17:14:45,217] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
kafka-1             | [2025-01-18 17:14:45,218] INFO [AddPartitionsToTxnSenderThread-1]: Starting (kafka.server.AddPartitionsToTxnManager)
kafka-1             | [2025-01-18 17:14:45,219] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,223] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,227] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
kafka-1             | [2025-01-18 17:14:45,248] INFO [TxnMarkerSenderThread-1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
kafka-1             | [2025-01-18 17:14:45,256] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
kafka-1             | [2025-01-18 17:14:45,287] INFO [Broker id=1] Transitioning 51 partition(s) to local followers. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,294] INFO [Broker id=1] Creating new partition __consumer_offsets-13 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,361] INFO [Partition __consumer_offsets-13 broker=1] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,364] INFO [Broker id=1] Follower __consumer_offsets-13 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-
1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,364] INFO [Broker id=1] Creating new partition __consumer_offsets-46 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,366] INFO [Partition __consumer_offsets-46 broker=1] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,366] INFO [Broker id=1] Follower __consumer_offsets-46 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-
1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,366] INFO [Broker id=1] Creating new partition __consumer_offsets-9 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,367] INFO [Partition __consumer_offsets-9 broker=1] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,367] INFO [Broker id=1] Follower __consumer_offsets-9 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-1
) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,368] INFO [Broker id=1] Creating new partition __consumer_offsets-42 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,370] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,371] INFO [Broker id=1] Follower __consumer_offsets-42 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-
1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,371] INFO [Broker id=1] Creating new partition __consumer_offsets-21 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,373] INFO [Partition __consumer_offsets-21 broker=1] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,373] INFO [Broker id=1] Follower __consumer_offsets-21 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-
1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,373] INFO [Broker id=1] Creating new partition __consumer_offsets-17 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,375] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,375] INFO [Broker id=1] Follower __consumer_offsets-17 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-
1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,376] INFO [Broker id=1] Creating new partition __consumer_offsets-30 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,379] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,379] INFO [Broker id=1] Follower __consumer_offsets-30 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-
1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,379] INFO [Broker id=1] Creating new partition __consumer_offsets-26 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,380] INFO [Partition __consumer_offsets-26 broker=1] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,381] INFO [Broker id=1] Follower __consumer_offsets-26 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-
1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,381] INFO [Broker id=1] Creating new partition __consumer_offsets-5 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,382] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,382] INFO [Broker id=1] Follower __consumer_offsets-5 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-1
) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,383] INFO [Broker id=1] Creating new partition __consumer_offsets-38 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,390] INFO [Partition __consumer_offsets-38 broker=1] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,390] INFO [Broker id=1] Follower __consumer_offsets-38 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-
1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,391] INFO [Broker id=1] Creating new partition __consumer_offsets-1 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,394] INFO [Partition __consumer_offsets-1 broker=1] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,395] INFO [Broker id=1] Follower __consumer_offsets-1 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-1
) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,395] INFO [Broker id=1] Creating new partition __consumer_offsets-34 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,397] INFO [Partition __consumer_offsets-34 broker=1] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,397] INFO [Broker id=1] Follower __consumer_offsets-34 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-
1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,397] INFO [Broker id=1] Creating new partition __consumer_offsets-16 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,398] INFO [Partition __consumer_offsets-16 broker=1] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,398] INFO [Broker id=1] Follower __consumer_offsets-16 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-
1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,398] INFO [Broker id=1] Creating new partition __consumer_offsets-45 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,399] INFO [Partition __consumer_offsets-45 broker=1] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,399] INFO [Broker id=1] Follower __consumer_offsets-45 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-
1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,400] INFO [Broker id=1] Creating new partition __consumer_offsets-12 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,401] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,401] INFO [Broker id=1] Follower __consumer_offsets-12 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-
1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,402] INFO [Broker id=1] Creating new partition __consumer_offsets-41 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,415] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,415] INFO [Broker id=1] Follower __consumer_offsets-41 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-
1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,416] INFO [Broker id=1] Creating new partition __consumer_offsets-24 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,418] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,418] INFO [Broker id=1] Follower __consumer_offsets-24 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-
1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,418] INFO [Broker id=1] Creating new partition __consumer_offsets-20 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,420] INFO [Partition __consumer_offsets-20 broker=1] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,420] INFO [Broker id=1] Follower __consumer_offsets-20 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-
1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,420] INFO [Broker id=1] Creating new partition __consumer_offsets-49 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,421] INFO [Partition __consumer_offsets-49 broker=1] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,421] INFO [Broker id=1] Follower __consumer_offsets-49 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-
1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,422] INFO [Broker id=1] Creating new partition __consumer_offsets-0 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,423] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,423] INFO [Broker id=1] Follower __consumer_offsets-0 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-1
) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,423] INFO [Broker id=1] Creating new partition __consumer_offsets-29 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,436] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,436] INFO [Broker id=1] Follower __consumer_offsets-29 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-
1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,436] INFO [Broker id=1] Creating new partition __consumer_offsets-25 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,437] INFO [Partition __consumer_offsets-25 broker=1] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,438] INFO [Broker id=1] Follower __consumer_offsets-25 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-
1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,438] INFO [Broker id=1] Creating new partition __consumer_offsets-8 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,439] INFO [Partition __consumer_offsets-8 broker=1] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,440] INFO [Broker id=1] Follower __consumer_offsets-8 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-1
) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,440] INFO [Broker id=1] Creating new partition __consumer_offsets-37 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,441] INFO [Partition __consumer_offsets-37 broker=1] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,441] INFO [Broker id=1] Follower __consumer_offsets-37 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-
1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,441] INFO [Broker id=1] Creating new partition __consumer_offsets-4 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,442] INFO [Partition __consumer_offsets-4 broker=1] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,443] INFO [Broker id=1] Follower __consumer_offsets-4 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-1
) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,443] INFO [Broker id=1] Creating new partition __consumer_offsets-33 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,444] INFO [Partition __consumer_offsets-33 broker=1] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,444] INFO [Broker id=1] Follower __consumer_offsets-33 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-
1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,445] INFO [Broker id=1] Creating new partition __consumer_offsets-15 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,458] INFO [Partition __consumer_offsets-15 broker=1] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,458] INFO [Broker id=1] Follower __consumer_offsets-15 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-
1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,458] INFO [Broker id=1] Creating new partition __consumer_offsets-48 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,460] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,461] INFO [Broker id=1] Follower __consumer_offsets-48 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-
1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,461] INFO [Broker id=1] Creating new partition __consumer_offsets-11 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,462] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,462] INFO [Broker id=1] Follower __consumer_offsets-11 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-
1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,463] INFO [Broker id=1] Creating new partition __consumer_offsets-44 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,464] INFO [Partition __consumer_offsets-44 broker=1] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,464] INFO [Broker id=1] Follower __consumer_offsets-44 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-
1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,465] INFO [Broker id=1] Creating new partition __consumer_offsets-23 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,466] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,466] INFO [Broker id=1] Follower __consumer_offsets-23 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-
1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,466] INFO [Broker id=1] Creating new partition test-notifications-0 with topic id fBG_L4UIQeqZIcMy-eDkkw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,468] INFO [Partition test-notifications-0 broker=1] Log loaded for partition test-notifications-0 with initial high watermark 20 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,469] INFO [Broker id=1] Follower test-notifications-0 starts at leader epoch 45 from offset 20 with partition epoch 45 and high watermark 20. Current leader is -1. Previous leader Some(
-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,470] INFO [Broker id=1] Creating new partition __consumer_offsets-19 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,474] INFO [Partition __consumer_offsets-19 broker=1] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,474] INFO [Broker id=1] Follower __consumer_offsets-19 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-
1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,474] INFO [Broker id=1] Creating new partition __consumer_offsets-32 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,476] INFO [Partition __consumer_offsets-32 broker=1] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,476] INFO [Broker id=1] Follower __consumer_offsets-32 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-
1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,476] INFO [Broker id=1] Creating new partition __consumer_offsets-28 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,479] INFO [Partition __consumer_offsets-28 broker=1] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,480] INFO [Broker id=1] Follower __consumer_offsets-28 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-
1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,480] INFO [Broker id=1] Creating new partition __consumer_offsets-7 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,482] INFO [Partition __consumer_offsets-7 broker=1] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,482] INFO [Broker id=1] Follower __consumer_offsets-7 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-1
) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,482] INFO [Broker id=1] Creating new partition __consumer_offsets-40 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,483] INFO [Partition __consumer_offsets-40 broker=1] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,483] INFO [Broker id=1] Follower __consumer_offsets-40 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-
1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,484] INFO [Broker id=1] Creating new partition __consumer_offsets-3 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,485] INFO [Partition __consumer_offsets-3 broker=1] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,485] INFO [Broker id=1] Follower __consumer_offsets-3 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-1
) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,485] INFO [Broker id=1] Creating new partition __consumer_offsets-36 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,487] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,487] INFO [Broker id=1] Follower __consumer_offsets-36 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-
1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,487] INFO [Broker id=1] Creating new partition __consumer_offsets-47 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,488] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,492] INFO [Broker id=1] Follower __consumer_offsets-47 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-
1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,496] INFO [Broker id=1] Creating new partition __consumer_offsets-14 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,498] INFO [Partition __consumer_offsets-14 broker=1] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,499] INFO [Broker id=1] Follower __consumer_offsets-14 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-
1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,499] INFO [Broker id=1] Creating new partition __consumer_offsets-43 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,500] INFO [Partition __consumer_offsets-43 broker=1] Log loaded for partition __consumer_offsets-43 with initial high watermark 40 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,500] INFO [Broker id=1] Follower __consumer_offsets-43 starts at leader epoch 45 from offset 40 with partition epoch 45 and high watermark 40. Current leader is -1. Previous leader Some
(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,501] INFO [Broker id=1] Creating new partition __consumer_offsets-10 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,502] INFO [Partition __consumer_offsets-10 broker=1] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,502] INFO [Broker id=1] Follower __consumer_offsets-10 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-
1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,502] INFO [Broker id=1] Creating new partition __consumer_offsets-22 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,503] INFO [Partition __consumer_offsets-22 broker=1] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,504] INFO [Broker id=1] Follower __consumer_offsets-22 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-
1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,504] INFO [Broker id=1] Creating new partition __consumer_offsets-18 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,506] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,508] INFO [Broker id=1] Follower __consumer_offsets-18 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-
1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,508] INFO [Broker id=1] Creating new partition __consumer_offsets-31 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,511] INFO [Partition __consumer_offsets-31 broker=1] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,511] INFO [Broker id=1] Follower __consumer_offsets-31 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-
1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,511] INFO [Broker id=1] Creating new partition __consumer_offsets-27 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,514] INFO [Partition __consumer_offsets-27 broker=1] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,514] INFO [Broker id=1] Follower __consumer_offsets-27 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-
1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,515] INFO [Broker id=1] Creating new partition __consumer_offsets-39 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,516] INFO [Partition __consumer_offsets-39 broker=1] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,516] INFO [Broker id=1] Follower __consumer_offsets-39 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-
1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,517] INFO [Broker id=1] Creating new partition __consumer_offsets-6 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,518] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,518] INFO [Broker id=1] Follower __consumer_offsets-6 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-1
) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,519] INFO [Broker id=1] Creating new partition __consumer_offsets-35 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,520] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,521] INFO [Broker id=1] Follower __consumer_offsets-35 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-
1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,521] INFO [Broker id=1] Creating new partition __consumer_offsets-2 with topic id OyIb1O_sRg6y81AbaHRyQw. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,522] INFO [Partition __consumer_offsets-2 broker=1] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
kafka-1             | [2025-01-18 17:14:45,523] INFO [Broker id=1] Follower __consumer_offsets-2 starts at leader epoch 45 from offset 0 with partition epoch 45 and high watermark 0. Current leader is -1. Previous leader Some(-1
) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,528] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-49, __consumer_offsets-38, __consumer_offsets-16, __consumer_offsets-27, __consumer_o
ffsets-8, __consumer_offsets-19, __consumer_offsets-2, __consumer_offsets-13, __consumer_offsets-35, __consumer_offsets-24, __consumer_offsets-46, __consumer_offsets-5, __consumer_offsets-43, __consumer_offsets-21, __consumer_of
fsets-32, __consumer_offsets-10, __consumer_offsets-37, __consumer_offsets-48, __consumer_offsets-29, __consumer_offsets-40, __consumer_offsets-18, __consumer_offsets-7, __consumer_offsets-45, __consumer_offsets-34, __consumer_o
ffsets-23, test-notifications-0, __consumer_offsets-26, __consumer_offsets-4, __consumer_offsets-15, __consumer_offsets-42, __consumer_offsets-20, __consumer_offsets-9, __consumer_offsets-31, __consumer_offsets-12, __consumer_of
fsets-1, __consumer_offsets-17, __consumer_offsets-28, __consumer_offsets-6, __consumer_offsets-39, __consumer_offsets-44, __consumer_offsets-36, __consumer_offsets-47, __consumer_offsets-25, __consumer_offsets-3, __consumer_off
sets-14, __consumer_offsets-41, __consumer_offsets-30, __consumer_offsets-33, __consumer_offsets-11, __consumer_offsets-22, __consumer_offsets-0) (kafka.server.ReplicaFetcherManager)
kafka-1             | [2025-01-18 17:14:45,530] INFO [Broker id=1] Stopped fetchers as part of become-follower for 51 partitions (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,541] INFO [Broker id=1] Started fetchers as part of become-follower for 51 partitions (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,591] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 13 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,594] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,595] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 46 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,595] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,595] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 9 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,595] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,595] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 42 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,595] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,595] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 21 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,595] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,595] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 17 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,596] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,596] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 30 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,596] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,596] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 26 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,596] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,596] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 5 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,596] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,596] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 38 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,596] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,596] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 1 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,596] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,597] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 34 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,597] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,597] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 16 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,597] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,597] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 45 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,597] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,597] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 12 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,597] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,597] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 41 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,597] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,597] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 24 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,597] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,597] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 20 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,597] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,597] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 49 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,597] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,597] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 0 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,597] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,597] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 29 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,597] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,598] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 25 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,598] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,598] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 8 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
calendar-scheduler  | Топик успешно создан!
kafka-1             | [2025-01-18 17:14:45,598] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
calendar-scheduler  | [INFO] 2025/01/18 17:14:47 Сервис по очистке старых событий запущен
kafka-1             | [2025-01-18 17:14:45,598] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 37 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,598] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,598] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 4 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,598] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,598] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 33 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,598] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,598] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 15 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,598] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,598] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 48 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,598] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,598] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 11 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,599] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,599] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 44 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,599] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,599] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 23 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,599] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,599] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 19 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,599] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,599] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 32 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,599] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,599] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 28 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,599] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,599] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 7 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,599] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,599] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 40 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,599] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,599] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 3 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,599] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,600] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 36 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,600] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,600] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 47 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,600] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,600] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 14 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,600] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,600] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 43 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,600] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,600] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 10 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,600] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,600] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 22 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,600] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,600] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 18 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,600] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,600] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 31 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,600] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,600] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 27 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,600] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,600] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 39 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,600] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,600] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 6 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,600] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,600] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 35 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,600] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,600] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 2 in epoch OptionalInt[45] (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:45,600] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,601] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-13 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordina
tor.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,601] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-46 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordina
tor.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,601] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-9 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinat
or.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,601] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-42 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordina
tor.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,602] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-21 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordina
tor.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,602] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-17 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordina
tor.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,602] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-30 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordina
tor.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,602] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-26 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordina
tor.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,603] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-5 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinat
or.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,607] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-38 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordina
tor.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,608] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-1 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinat
or.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,608] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-34 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordina
tor.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,608] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-16 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordina
tor.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,608] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-45 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordina
tor.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,609] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-12 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordina
tor.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,609] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-41 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordina
tor.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,609] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-24 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordina
tor.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,610] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-20 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordina
tor.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,610] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-49 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordina
tor.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,611] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-0 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinat
or.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,611] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-29 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordina
tor.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,611] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-25 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordina
tor.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,611] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-8 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinat
or.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,611] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-37 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordina
tor.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,612] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-4 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinat
or.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,612] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-33 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordina
tor.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,612] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-15 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordina
tor.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,612] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-48 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordina
tor.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,612] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-11 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordina
tor.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,613] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-44 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordina
tor.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,613] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-23 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordina
tor.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,631] INFO [DynamicConfigPublisher broker id=1] Updating topic __consumer_offsets with new configuration : cleanup.policy -> compact,segment.bytes -> 104857600,compression.type -> produc
er (kafka.server.metadata.DynamicConfigPublisher)
kafka-1             | [2025-01-18 17:14:45,641] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-19 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordina
tor.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,641] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-32 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordina
tor.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,641] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-28 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordina
tor.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,642] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-7 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinat
or.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,642] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-40 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordina
tor.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,642] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-3 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinat
or.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,642] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-36 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordina
tor.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,643] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-47 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordina
tor.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,643] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-14 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordina
tor.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,643] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-43 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordina
tor.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,643] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-10 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordina
tor.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,643] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-22 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordina
tor.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,643] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-18 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordina
tor.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,643] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-31 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordina
tor.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,644] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-27 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordina
tor.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,644] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-39 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordina
tor.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,644] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-6 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinat
or.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,644] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-35 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordina
tor.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,644] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-2 for coordinator epoch OptionalInt[45]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinat
or.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:45,685] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing BrokerRegistrationTracker(id=1) with a snapshot at offset 62596 (org.apache.kafka.image.loader.MetadataLoader)
kafka-1             | [2025-01-18 17:14:45,685] INFO [BrokerServer id=1] Finished waiting for the initial broker metadata update to be published (kafka.server.BrokerServer)
kafka-1             | [2025-01-18 17:14:45,694] INFO KafkaConfig values:
kafka-1             |   advertised.listeners = PLAINTEXT://kafka:9092
kafka-1             |   alter.config.policy.class.name = null
kafka-1             |   alter.log.dirs.replication.quota.window.num = 11
kafka-1             |   alter.log.dirs.replication.quota.window.size.seconds = 1
kafka-1             |   authorizer.class.name =
kafka-1             |   auto.create.topics.enable = true
kafka-1             |   auto.include.jmx.reporter = true
kafka-1             |   auto.leader.rebalance.enable = true
kafka-1             |   background.threads = 10
kafka-1             |   broker.heartbeat.interval.ms = 2000
kafka-1             |   broker.id = 1
kafka-1             |   broker.id.generation.enable = true
kafka-1             |   broker.rack = null
kafka-1             |   broker.session.timeout.ms = 9000
kafka-1             |   client.quota.callback.class = null
kafka-1             |   compression.gzip.level = -1
kafka-1             |   compression.lz4.level = 9
kafka-1             |   compression.type = producer
kafka-1             |   compression.zstd.level = 3
kafka-1             |   connection.failed.authentication.delay.ms = 100
kafka-1             |   connections.max.idle.ms = 600000
kafka-1             |   connections.max.reauth.ms = 0
kafka-1             |   control.plane.listener.name = null
kafka-1             |   controlled.shutdown.enable = true
kafka-1             |   controlled.shutdown.max.retries = 3
kafka-1             |   controlled.shutdown.retry.backoff.ms = 5000
kafka-1             |   controller.listener.names = CONTROLLER
kafka-1             |   controller.quorum.append.linger.ms = 25
kafka-1             |   controller.quorum.bootstrap.servers = []
kafka-1             |   controller.quorum.election.backoff.max.ms = 1000
kafka-1             |   controller.quorum.election.timeout.ms = 1000
kafka-1             |   controller.quorum.fetch.timeout.ms = 2000
kafka-1             |   controller.quorum.request.timeout.ms = 2000
kafka-1             |   controller.quorum.retry.backoff.ms = 20
kafka-1             |   controller.quorum.voters = [1@127.0.0.1:9093]
kafka-1             |   controller.quota.window.num = 11
kafka-1             |   controller.quota.window.size.seconds = 1
kafka-1             |   controller.socket.timeout.ms = 30000
kafka-1             |   create.topic.policy.class.name = null
kafka-1             |   default.replication.factor = 1
kafka-1             |   delegation.token.expiry.check.interval.ms = 3600000
kafka-1             |   delegation.token.expiry.time.ms = 86400000
kafka-1             |   delegation.token.master.key = null
kafka-1             |   delegation.token.max.lifetime.ms = 604800000
kafka-1             |   delegation.token.secret.key = null
kafka-1             |   delete.records.purgatory.purge.interval.requests = 1
kafka-1             |   delete.topic.enable = true
kafka-1             |   early.start.listeners = null
kafka-1             |   eligible.leader.replicas.enable = false
kafka-1             |   fetch.max.bytes = 57671680
kafka-1             |   fetch.purgatory.purge.interval.requests = 1000
kafka-1             |   group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
kafka-1             |   group.consumer.heartbeat.interval.ms = 5000
kafka-1             |   group.consumer.max.heartbeat.interval.ms = 15000
kafka-1             |   group.consumer.max.session.timeout.ms = 60000
kafka-1             |   group.consumer.max.size = 2147483647
kafka-1             |   group.consumer.migration.policy = disabled
kafka-1             |   group.consumer.min.heartbeat.interval.ms = 5000
kafka-1             |   group.consumer.min.session.timeout.ms = 45000
kafka-1             |   group.consumer.session.timeout.ms = 45000
kafka-1             |   group.coordinator.append.linger.ms = 10
kafka-1             |   group.coordinator.new.enable = false
kafka-1             |   group.coordinator.rebalance.protocols = [classic]
kafka-1             |   group.coordinator.threads = 1
kafka-1             |   group.initial.rebalance.delay.ms = 3000
kafka-1             |   group.max.session.timeout.ms = 1800000
kafka-1             |   group.max.size = 2147483647
kafka-1             |   group.min.session.timeout.ms = 6000
kafka-1             |   group.share.delivery.count.limit = 5
kafka-1             |   group.share.enable = false
kafka-1             |   group.share.heartbeat.interval.ms = 5000
kafka-1             |   group.share.max.groups = 10
kafka-1             |   group.share.max.heartbeat.interval.ms = 15000
kafka-1             |   group.share.max.record.lock.duration.ms = 60000
kafka-1             |   group.share.max.session.timeout.ms = 60000
kafka-1             |   group.share.max.size = 200
kafka-1             |   group.share.min.heartbeat.interval.ms = 5000
kafka-1             |   group.share.min.record.lock.duration.ms = 15000
kafka-1             |   group.share.min.session.timeout.ms = 45000
kafka-1             |   group.share.partition.max.record.locks = 200
kafka-1             |   group.share.record.lock.duration.ms = 30000
kafka-1             |   group.share.session.timeout.ms = 45000
kafka-1             |   initial.broker.registration.timeout.ms = 60000
kafka-1             |   inter.broker.listener.name = null
kafka-1             |   inter.broker.protocol.version = 3.9-IV0
kafka-1             |   kafka.metrics.polling.interval.secs = 10
kafka-1             |   kafka.metrics.reporters = []
kafka-1             |   leader.imbalance.check.interval.seconds = 300
kafka-1             |   leader.imbalance.per.broker.percentage = 10
kafka-1             |   listener.security.protocol.map = PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT
kafka-1             |   listeners = PLAINTEXT://:9092,CONTROLLER://:9093
kafka-1             |   log.cleaner.backoff.ms = 15000
kafka-1             |   log.cleaner.dedupe.buffer.size = 134217728
kafka-1             |   log.cleaner.delete.retention.ms = 86400000
kafka-1             |   log.cleaner.enable = true
kafka-1             |   log.cleaner.io.buffer.load.factor = 0.9
kafka-1             |   log.cleaner.io.buffer.size = 524288
kafka-1             |   log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
kafka-1             |   log.cleaner.max.compaction.lag.ms = 9223372036854775807
kafka-1             |   log.cleaner.min.cleanable.ratio = 0.5
kafka-1             |   log.cleaner.min.compaction.lag.ms = 0
kafka-1             |   log.cleaner.threads = 1
kafka-1             |   log.cleanup.policy = [delete]
kafka-1             |   log.dir = /tmp/kafka-logs
kafka-1             |   log.dir.failure.timeout.ms = 30000
kafka-1             |   log.dirs = /bitnami/kafka/data
kafka-1             |   log.flush.interval.messages = 9223372036854775807
kafka-1             |   log.flush.interval.ms = null
kafka-1             |   log.flush.offset.checkpoint.interval.ms = 60000
kafka-1             |   log.flush.scheduler.interval.ms = 9223372036854775807
kafka-1             |   log.flush.start.offset.checkpoint.interval.ms = 60000
kafka-1             |   log.index.interval.bytes = 4096
kafka-1             |   log.index.size.max.bytes = 10485760
kafka-1             |   log.initial.task.delay.ms = 30000
kafka-1             |   log.local.retention.bytes = -2
kafka-1             |   log.local.retention.ms = -2
kafka-1             |   log.message.downconversion.enable = true
kafka-1             |   log.message.format.version = 3.0-IV1
kafka-1             |   log.message.timestamp.after.max.ms = 9223372036854775807
kafka-1             |   log.message.timestamp.before.max.ms = 9223372036854775807
kafka-1             |   log.message.timestamp.difference.max.ms = 9223372036854775807
kafka-1             |   log.message.timestamp.type = CreateTime
kafka-1             |   log.preallocate = false
kafka-1             |   log.retention.bytes = -1
kafka-1             |   log.retention.check.interval.ms = 300000
kafka-1             |   log.retention.hours = 168
kafka-1             |   log.retention.minutes = null
kafka-1             |   log.retention.ms = null
kafka-1             |   log.roll.hours = 168
kafka-1             |   log.roll.jitter.hours = 0
kafka-1             |   log.roll.jitter.ms = null
kafka-1             |   log.roll.ms = null
kafka-1             |   log.segment.bytes = 1073741824
kafka-1             |   log.segment.delete.delay.ms = 60000
kafka-1             |   max.connection.creation.rate = 2147483647
kafka-1             |   max.connections = 2147483647
kafka-1             |   max.connections.per.ip = 2147483647
kafka-1             |   max.connections.per.ip.overrides =
kafka-1             |   max.incremental.fetch.session.cache.slots = 1000
kafka-1             |   max.request.partition.size.limit = 2000
kafka-1             |   message.max.bytes = 1048588
kafka-1             |   metadata.log.dir = null
kafka-1             |   metadata.log.max.record.bytes.between.snapshots = 20971520
kafka-1             |   metadata.log.max.snapshot.interval.ms = 3600000
kafka-1             |   metadata.log.segment.bytes = 1073741824
kafka-1             |   metadata.log.segment.min.bytes = 8388608
kafka-1             |   metadata.log.segment.ms = 604800000
kafka-1             |   metadata.max.idle.interval.ms = 500
kafka-1             |   metadata.max.retention.bytes = 104857600
kafka-1             |   metadata.max.retention.ms = 604800000
kafka-1             |   metric.reporters = []
kafka-1             |   metrics.num.samples = 2
kafka-1             |   metrics.recording.level = INFO
kafka-1             |   metrics.sample.window.ms = 30000
kafka-1             |   min.insync.replicas = 1
kafka-1             |   node.id = 1
kafka-1             |   num.io.threads = 8
kafka-1             |   num.network.threads = 3
kafka-1             |   num.partitions = 1
kafka-1             |   num.recovery.threads.per.data.dir = 1
kafka-1             |   num.replica.alter.log.dirs.threads = null
kafka-1             |   num.replica.fetchers = 1
kafka-1             |   offset.metadata.max.bytes = 4096
kafka-1             |   offsets.commit.required.acks = -1
kafka-1             |   offsets.commit.timeout.ms = 5000
kafka-1             |   offsets.load.buffer.size = 5242880
kafka-1             |   offsets.retention.check.interval.ms = 600000
kafka-1             |   offsets.retention.minutes = 10080
kafka-1             |   offsets.topic.compression.codec = 0
kafka-1             |   offsets.topic.num.partitions = 50
kafka-1             |   offsets.topic.replication.factor = 1
kafka-1             |   offsets.topic.segment.bytes = 104857600
kafka-1             |   password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
kafka-1             |   password.encoder.iterations = 4096
kafka-1             |   password.encoder.key.length = 128
kafka-1             |   password.encoder.keyfactory.algorithm = null
kafka-1             |   password.encoder.old.secret = null
kafka-1             |   password.encoder.secret = null
kafka-1             |   principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
kafka-1             |   process.roles = [broker, controller]
kafka-1             |   producer.id.expiration.check.interval.ms = 600000
kafka-1             |   producer.id.expiration.ms = 86400000
kafka-1             |   producer.purgatory.purge.interval.requests = 1000
kafka-1             |   queued.max.request.bytes = -1
kafka-1             |   queued.max.requests = 500
kafka-1             |   quota.window.num = 11
kafka-1             |   quota.window.size.seconds = 1
kafka-1             |   remote.fetch.max.wait.ms = 500
kafka-1             |   remote.log.index.file.cache.total.size.bytes = 1073741824
kafka-1             |   remote.log.manager.copier.thread.pool.size = -1
kafka-1             |   remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
kafka-1             |   remote.log.manager.copy.quota.window.num = 11
kafka-1             |   remote.log.manager.copy.quota.window.size.seconds = 1
kafka-1             |   remote.log.manager.expiration.thread.pool.size = -1
kafka-1             |   remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
kafka-1             |   remote.log.manager.fetch.quota.window.num = 11
kafka-1             |   remote.log.manager.fetch.quota.window.size.seconds = 1
kafka-1             |   remote.log.manager.task.interval.ms = 30000
kafka-1             |   remote.log.manager.task.retry.backoff.max.ms = 30000
kafka-1             |   remote.log.manager.task.retry.backoff.ms = 500
kafka-1             |   remote.log.manager.task.retry.jitter = 0.2
kafka-1             |   remote.log.manager.thread.pool.size = 10
kafka-1             |   remote.log.metadata.custom.metadata.max.bytes = 128
kafka-1             |   remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
kafka-1             |   remote.log.metadata.manager.class.path = null
kafka-1             |   remote.log.metadata.manager.impl.prefix = rlmm.config.
kafka-1             |   remote.log.metadata.manager.listener.name = null
kafka-1             |   remote.log.reader.max.pending.tasks = 100
kafka-1             |   remote.log.reader.threads = 10
kafka-1             |   remote.log.storage.manager.class.name = null
kafka-1             |   remote.log.storage.manager.class.path = null
kafka-1             |   remote.log.storage.manager.impl.prefix = rsm.config.
kafka-1             |   remote.log.storage.system.enable = false
kafka-1             |   replica.fetch.backoff.ms = 1000
kafka-1             |   replica.fetch.max.bytes = 1048576
kafka-1             |   replica.fetch.min.bytes = 1
kafka-1             |   replica.fetch.response.max.bytes = 10485760
kafka-1             |   replica.fetch.wait.max.ms = 500
kafka-1             |   replica.high.watermark.checkpoint.interval.ms = 5000
kafka-1             |   replica.lag.time.max.ms = 30000
kafka-1             |   replica.selector.class = null
kafka-1             |   replica.socket.receive.buffer.bytes = 65536
kafka-1             |   replica.socket.timeout.ms = 30000
kafka-1             |   replication.quota.window.num = 11
kafka-1             |   replication.quota.window.size.seconds = 1
kafka-1             |   request.timeout.ms = 30000
kafka-1             |   reserved.broker.max.id = 1000
kafka-1             |   sasl.client.callback.handler.class = null
kafka-1             |   sasl.enabled.mechanisms = [PLAIN, SCRAM-SHA-256, SCRAM-SHA-512]
kafka-1             |   sasl.jaas.config = null
kafka-1             |   sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafka-1             |   sasl.kerberos.min.time.before.relogin = 60000
kafka-1             |   sasl.kerberos.principal.to.local.rules = [DEFAULT]
kafka-1             |   sasl.kerberos.service.name = null
kafka-1             |   sasl.kerberos.ticket.renew.jitter = 0.05
kafka-1             |   sasl.kerberos.ticket.renew.window.factor = 0.8
kafka-1             |   sasl.login.callback.handler.class = null
kafka-1             |   sasl.login.class = null
kafka-1             |   sasl.login.connect.timeout.ms = null
kafka-1             |   sasl.login.read.timeout.ms = null
kafka-1             |   sasl.login.refresh.buffer.seconds = 300
kafka-1             |   sasl.login.refresh.min.period.seconds = 60
kafka-1             |   sasl.login.refresh.window.factor = 0.8
kafka-1             |   sasl.login.refresh.window.jitter = 0.05
kafka-1             |   sasl.login.retry.backoff.max.ms = 10000
kafka-1             |   sasl.login.retry.backoff.ms = 100
kafka-1             |   sasl.mechanism.controller.protocol = GSSAPI
kafka-1             |   sasl.mechanism.inter.broker.protocol = GSSAPI
kafka-1             |   sasl.oauthbearer.clock.skew.seconds = 30
kafka-1             |   sasl.oauthbearer.expected.audience = null
kafka-1             |   sasl.oauthbearer.expected.issuer = null
kafka-1             |   sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
kafka-1             |   sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
kafka-1             |   sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
kafka-1             |   sasl.oauthbearer.jwks.endpoint.url = null
kafka-1             |   sasl.oauthbearer.scope.claim.name = scope
kafka-1             |   sasl.oauthbearer.sub.claim.name = sub
kafka-1             |   sasl.oauthbearer.token.endpoint.url = null
kafka-1             |   sasl.server.callback.handler.class = null
kafka-1             |   sasl.server.max.receive.size = 524288
kafka-1             |   security.inter.broker.protocol = PLAINTEXT
kafka-1             |   security.providers = null
kafka-1             |   server.max.startup.time.ms = 9223372036854775807
kafka-1             |   socket.connection.setup.timeout.max.ms = 30000
kafka-1             |   socket.connection.setup.timeout.ms = 10000
kafka-1             |   socket.listen.backlog.size = 50
kafka-1             |   socket.receive.buffer.bytes = 102400
kafka-1             |   socket.request.max.bytes = 104857600
kafka-1             |   socket.send.buffer.bytes = 102400
kafka-1             |   ssl.allow.dn.changes = false
kafka-1             |   ssl.allow.san.changes = false
kafka-1             |   ssl.cipher.suites = []
kafka-1             |   ssl.client.auth = none
kafka-1             |   ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafka-1             |   ssl.endpoint.identification.algorithm = https
kafka-1             |   ssl.engine.factory.class = null
kafka-1             |   ssl.key.password = null
kafka-1             |   ssl.keymanager.algorithm = SunX509
kafka-1             |   ssl.keystore.certificate.chain = null
kafka-1             |   ssl.keystore.key = null
kafka-1             |   ssl.keystore.location = null
kafka-1             |   ssl.keystore.password = null
kafka-1             |   ssl.keystore.type = JKS
kafka-1             |   ssl.principal.mapping.rules = DEFAULT
kafka-1             |   ssl.protocol = TLSv1.3
kafka-1             |   ssl.provider = null
kafka-1             |   ssl.secure.random.implementation = null
kafka-1             |   ssl.trustmanager.algorithm = PKIX
kafka-1             |   ssl.truststore.certificates = null
kafka-1             |   ssl.truststore.location = null
kafka-1             |   ssl.truststore.password = null
kafka-1             |   ssl.truststore.type = JKS
kafka-1             |   telemetry.max.bytes = 1048576
kafka-1             |   transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
kafka-1             |   transaction.max.timeout.ms = 900000
kafka-1             |   transaction.partition.verification.enable = true
kafka-1             |   transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
kafka-1             |   transaction.state.log.load.buffer.size = 5242880
kafka-1             |   transaction.state.log.min.isr = 1
kafka-1             |   transaction.state.log.num.partitions = 50
kafka-1             |   transaction.state.log.replication.factor = 1
kafka-1             |   transaction.state.log.segment.bytes = 104857600
kafka-1             |   transactional.id.expiration.ms = 604800000
kafka-1             |   unclean.leader.election.enable = false
kafka-1             |   unclean.leader.election.interval.ms = 300000
kafka-1             |   unstable.api.versions.enable = false
kafka-1             |   unstable.feature.versions.enable = false
kafka-1             |   zookeeper.clientCnxnSocket = null
kafka-1             |   zookeeper.connect = null
kafka-1             |   zookeeper.connection.timeout.ms = null
kafka-1             |   zookeeper.max.in.flight.requests = 10
kafka-1             |   zookeeper.metadata.migration.enable = false
kafka-1             |   zookeeper.metadata.migration.min.batch.size = 200
kafka-1             |   zookeeper.session.timeout.ms = 18000
kafka-1             |   zookeeper.set.acl = false
kafka-1             |   zookeeper.ssl.cipher.suites = null
kafka-1             |   zookeeper.ssl.client.enable = false
kafka-1             |   zookeeper.ssl.crl.enable = false
kafka-1             |   zookeeper.ssl.enabled.protocols = null
kafka-1             |   zookeeper.ssl.endpoint.identification.algorithm = HTTPS
kafka-1             |   zookeeper.ssl.keystore.location = null
kafka-1             |   zookeeper.ssl.keystore.password = null
kafka-1             |   zookeeper.ssl.keystore.type = null
kafka-1             |   zookeeper.ssl.ocsp.enable = false
kafka-1             |   zookeeper.ssl.protocol = TLSv1.2
kafka-1             |   zookeeper.ssl.truststore.location = null
kafka-1             |   zookeeper.ssl.truststore.password = null
kafka-1             |   zookeeper.ssl.truststore.type = null
kafka-1             |  (kafka.server.KafkaConfig)
kafka-1             | [2025-01-18 17:14:45,727] INFO [BrokerServer id=1] Waiting for the broker to be unfenced (kafka.server.BrokerServer)
kafka-1             | [2025-01-18 17:14:45,730] INFO [QuorumController id=1] The request from broker 1 to unfence has been granted because it has caught up with the offset of its register broker record 62596. (org.apache.kafka.c
ontroller.BrokerHeartbeatManager)
kafka-1             | [2025-01-18 17:14:45,763] INFO [QuorumController id=1] handleBrokerUnfenced: changing 51 partition(s) (org.apache.kafka.controller.ReplicationControlManager)
kafka-1             | [2025-01-18 17:14:45,781] INFO [QuorumController id=1] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 1: BrokerRegistrationChangeRecord(brokerId=1, brokerEpoch=62596, fenced=-
1, inControlledShutdown=0, logDirs=[]) (org.apache.kafka.controller.ClusterControlManager)
kafka-1             | [2025-01-18 17:14:45,814] INFO [Broker id=1] Transitioning 51 partition(s) to local leaders. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,815] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-13, __consumer_offsets-46, __consumer_offsets-9, __consumer_offsets-42, __consumer_of
fsets-21, __consumer_offsets-17, __consumer_offsets-30, __consumer_offsets-26, __consumer_offsets-5, __consumer_offsets-38, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-16, __consumer_offsets-45, __consumer_of
fsets-12, __consumer_offsets-41, __consumer_offsets-24, __consumer_offsets-20, __consumer_offsets-49, __consumer_offsets-0, __consumer_offsets-29, __consumer_offsets-25, __consumer_offsets-8, __consumer_offsets-37, __consumer_of
fsets-4, __consumer_offsets-33, __consumer_offsets-15, __consumer_offsets-48, __consumer_offsets-11, __consumer_offsets-44, __consumer_offsets-23, test-notifications-0, __consumer_offsets-19, __consumer_offsets-32, __consumer_of
fsets-28, __consumer_offsets-7, __consumer_offsets-40, __consumer_offsets-3, __consumer_offsets-36, __consumer_offsets-47, __consumer_offsets-14, __consumer_offsets-43, __consumer_offsets-10, __consumer_offsets-22, __consumer_of
fsets-18, __consumer_offsets-31, __consumer_offsets-27, __consumer_offsets-39, __consumer_offsets-6, __consumer_offsets-35, __consumer_offsets-2) (kafka.server.ReplicaFetcherManager)
kafka-1             | [2025-01-18 17:14:45,816] INFO [BrokerLifecycleManager id=1] The broker has been unfenced. Transitioning from RECOVERY to RUNNING. (kafka.server.BrokerLifecycleManager)
kafka-1             | [2025-01-18 17:14:45,817] INFO [BrokerServer id=1] Finished waiting for the broker to be unfenced (kafka.server.BrokerServer)
kafka-1             | [2025-01-18 17:14:45,819] INFO authorizerStart completed for endpoint PLAINTEXT. Endpoint is now READY. (org.apache.kafka.server.network.EndpointReadyFutures)
kafka-1             | [2025-01-18 17:14:45,819] INFO [SocketServer listenerType=BROKER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
kafka-1             | [2025-01-18 17:14:45,820] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
kafka-1             | [2025-01-18 17:14:45,823] INFO [BrokerServer id=1] Waiting for all of the authorizer futures to be completed (kafka.server.BrokerServer)
kafka-1             | [2025-01-18 17:14:45,823] INFO [BrokerServer id=1] Finished waiting for all of the authorizer futures to be completed (kafka.server.BrokerServer)
kafka-1             | [2025-01-18 17:14:45,823] INFO [BrokerServer id=1] Waiting for all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)
kafka-1             | [2025-01-18 17:14:45,823] INFO [BrokerServer id=1] Finished waiting for all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)
kafka-1             | [2025-01-18 17:14:45,824] INFO [BrokerServer id=1] Transition from STARTING to STARTED (kafka.server.BrokerServer)
kafka-1             | [2025-01-18 17:14:45,825] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
kafka-1             | [2025-01-18 17:14:45,825] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
kafka-1             | [2025-01-18 17:14:45,825] INFO Kafka startTimeMs: 1737220485824 (org.apache.kafka.common.utils.AppInfoParser)
kafka-1             | [2025-01-18 17:14:45,827] INFO [KafkaRaftServer nodeId=1] Kafka Server started (kafka.server.KafkaRaftServer)
kafka-1             | [2025-01-18 17:14:45,838] INFO [Broker id=1] Leader __consumer_offsets-13 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1
], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,858] INFO [Broker id=1] Leader __consumer_offsets-46 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1
], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,873] INFO [Broker id=1] Leader __consumer_offsets-9 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1]
, adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,896] INFO [Broker id=1] Leader __consumer_offsets-42 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1
], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,910] INFO [Broker id=1] Leader __consumer_offsets-21 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1
], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,925] INFO [Broker id=1] Leader __consumer_offsets-17 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1
], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,938] INFO [Broker id=1] Leader __consumer_offsets-30 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1
], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,950] INFO [Broker id=1] Leader __consumer_offsets-26 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1
], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,964] INFO [Broker id=1] Leader __consumer_offsets-5 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1]
, adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,979] INFO [Broker id=1] Leader __consumer_offsets-38 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1
], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:45,994] INFO [Broker id=1] Leader __consumer_offsets-1 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1]
, adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:46,009] INFO [Broker id=1] Leader __consumer_offsets-34 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1
], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:46,041] INFO [Broker id=1] Leader __consumer_offsets-16 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1
], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:46,061] INFO [Broker id=1] Leader __consumer_offsets-45 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1
], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:46,073] INFO [Broker id=1] Leader __consumer_offsets-12 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1
], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:46,103] INFO [Broker id=1] Leader __consumer_offsets-41 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1
], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:46,117] INFO [Broker id=1] Leader __consumer_offsets-24 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1
], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:46,128] INFO [Broker id=1] Leader __consumer_offsets-20 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1
], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:46,141] INFO [Broker id=1] Leader __consumer_offsets-49 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1
], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:46,151] INFO [Broker id=1] Leader __consumer_offsets-0 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1]
, adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:46,165] INFO [Broker id=1] Leader __consumer_offsets-29 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1
], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:46,176] INFO [Broker id=1] Leader __consumer_offsets-25 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1
], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:46,189] INFO [Broker id=1] Leader __consumer_offsets-8 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1]
, adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:46,206] INFO [Broker id=1] Leader __consumer_offsets-37 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1
], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:46,218] INFO [Broker id=1] Leader __consumer_offsets-4 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1]
, adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:46,243] INFO [Broker id=1] Leader __consumer_offsets-33 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1
], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:46,270] INFO [Broker id=1] Leader __consumer_offsets-15 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1
], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:46,295] INFO [Broker id=1] Leader __consumer_offsets-48 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1
], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:46,316] INFO [Broker id=1] Leader __consumer_offsets-11 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1
], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:46,332] INFO [Broker id=1] Leader __consumer_offsets-44 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1
], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:46,355] INFO [Broker id=1] Leader __consumer_offsets-23 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1
], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:46,369] INFO [Broker id=1] Leader test-notifications-0 with topic id Some(fBG_L4UIQeqZIcMy-eDkkw) starts at leader epoch 46 from offset 20 with partition epoch 46, high watermark 20, ISR [
1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:46,385] INFO [Broker id=1] Leader __consumer_offsets-19 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1
], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:46,396] INFO [Broker id=1] Leader __consumer_offsets-32 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1
], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:46,409] INFO [Broker id=1] Leader __consumer_offsets-28 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1
], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:46,429] INFO [Broker id=1] Leader __consumer_offsets-7 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1]
, adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:46,441] INFO [Broker id=1] Leader __consumer_offsets-40 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1
], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:46,464] INFO [Broker id=1] Leader __consumer_offsets-3 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1]
, adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:46,477] INFO [Broker id=1] Leader __consumer_offsets-36 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1
], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:46,487] INFO [Broker id=1] Leader __consumer_offsets-47 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1
], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:46,499] INFO [Broker id=1] Leader __consumer_offsets-14 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1
], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:46,521] INFO [Broker id=1] Leader __consumer_offsets-43 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 40 with partition epoch 46, high watermark 40, ISR
[1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:46,537] INFO [Broker id=1] Leader __consumer_offsets-10 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1
], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:46,546] INFO [Broker id=1] Leader __consumer_offsets-22 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1
], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:46,556] INFO [Broker id=1] Leader __consumer_offsets-18 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1
], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:46,565] INFO [Broker id=1] Leader __consumer_offsets-31 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1
], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:46,575] INFO [Broker id=1] Leader __consumer_offsets-27 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1
], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:46,587] INFO [Broker id=1] Leader __consumer_offsets-39 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1
], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:46,601] INFO [Broker id=1] Leader __consumer_offsets-6 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1]
, adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:46,611] INFO [Broker id=1] Leader __consumer_offsets-35 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1
], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:46,621] INFO [Broker id=1] Leader __consumer_offsets-2 with topic id Some(OyIb1O_sRg6y81AbaHRyQw) starts at leader epoch 46 from offset 0 with partition epoch 46, high watermark 0, ISR [1]
, adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 45. (state.change.logger)
kafka-1             | [2025-01-18 17:14:46,644] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 13 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,645] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,651] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 46 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,651] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,651] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 9 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,651] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,651] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 42 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,651] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,651] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 21 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,651] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,651] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 17 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,651] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,651] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 30 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,651] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,651] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 26 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,651] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,651] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 5 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,651] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,651] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 38 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,651] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,651] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 1 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,651] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,651] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 34 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,651] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,651] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 16 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,651] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,651] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 45 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,651] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,651] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 12 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,651] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,651] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 41 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,651] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,651] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 24 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,651] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,651] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 20 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,651] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,651] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 49 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,651] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,651] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 0 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,651] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,651] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 29 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,651] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 25 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 8 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 37 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 4 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 33 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 15 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 48 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 11 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 44 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 23 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 19 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 32 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 28 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 7 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 40 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 3 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 36 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 47 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 14 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 43 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 10 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 22 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 18 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 31 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,652] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 27 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,653] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,653] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 39 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,653] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,653] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 6 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,653] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,653] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 35 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,653] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,653] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 2 in epoch 46 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,653] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 46 (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,680] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-13 in 29 milliseconds for epoch 46, of which 6 milliseconds was spent in
the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,680] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 29 milliseconds for epoch 46, of which 29 milliseconds was spent in
 the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,681] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 30 milliseconds for epoch 46, of which 30 milliseconds was spent in
the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,682] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 31 milliseconds for epoch 46, of which 30 milliseconds was spent in
 the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,682] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 31 milliseconds for epoch 46, of which 31 milliseconds was spent in
 the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,683] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 32 milliseconds for epoch 46, of which 31 milliseconds was spent in
 the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,691] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 40 milliseconds for epoch 46, of which 32 milliseconds was spent in
 the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,693] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 42 milliseconds for epoch 46, of which 42 milliseconds was spent in
 the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,694] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 43 milliseconds for epoch 46, of which 43 milliseconds was spent in
the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,695] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 44 milliseconds for epoch 46, of which 43 milliseconds was spent in
 the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,696] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 44 milliseconds for epoch 46, of which 44 milliseconds was spent in
the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,696] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 45 milliseconds for epoch 46, of which 45 milliseconds was spent in
 the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,697] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 46 milliseconds for epoch 46, of which 45 milliseconds was spent in
 the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,697] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 46 milliseconds for epoch 46, of which 46 milliseconds was spent in
 the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,698] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 47 milliseconds for epoch 46, of which 47 milliseconds was spent in
 the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,699] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 48 milliseconds for epoch 46, of which 47 milliseconds was spent in
 the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,699] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 48 milliseconds for epoch 46, of which 48 milliseconds was spent in
 the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,700] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 49 milliseconds for epoch 46, of which 48 milliseconds was spent in
 the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,700] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-49 in 49 milliseconds for epoch 46, of which 49 milliseconds was spent in
 the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,701] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 50 milliseconds for epoch 46, of which 49 milliseconds was spent in
the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,701] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 49 milliseconds for epoch 46, of which 49 milliseconds was spent in
 the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,704] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 51 milliseconds for epoch 46, of which 50 milliseconds was spent in
 the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,705] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 53 milliseconds for epoch 46, of which 52 milliseconds was spent in
the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,706] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-37 in 54 milliseconds for epoch 46, of which 54 milliseconds was spent in
 the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,707] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 55 milliseconds for epoch 46, of which 54 milliseconds was spent in
the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,708] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 56 milliseconds for epoch 46, of which 55 milliseconds was spent in
 the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,711] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 59 milliseconds for epoch 46, of which 57 milliseconds was spent in
 the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,712] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 60 milliseconds for epoch 46, of which 59 milliseconds was spent in
 the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,713] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 60 milliseconds for epoch 46, of which 60 milliseconds was spent in
 the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,713] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 61 milliseconds for epoch 46, of which 61 milliseconds was spent in
 the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,714] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 62 milliseconds for epoch 46, of which 61 milliseconds was spent in
 the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,714] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-19 in 62 milliseconds for epoch 46, of which 62 milliseconds was spent in
 the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,715] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 63 milliseconds for epoch 46, of which 62 milliseconds was spent in
 the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,715] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 63 milliseconds for epoch 46, of which 63 milliseconds was spent in
 the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,716] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 64 milliseconds for epoch 46, of which 63 milliseconds was spent in
the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,716] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 64 milliseconds for epoch 46, of which 64 milliseconds was spent in
 the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,721] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 68 milliseconds for epoch 46, of which 65 milliseconds was spent in
the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,722] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 70 milliseconds for epoch 46, of which 69 milliseconds was spent in
 the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,723] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 71 milliseconds for epoch 46, of which 70 milliseconds was spent in
 the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,723] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 71 milliseconds for epoch 46, of which 71 milliseconds was spent in
 the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,778] INFO Loaded member MemberMetadata(memberId=calendar-sender@97282df6557f (github.com/segmentio/kafka-go)-2b8d8cf1-6fa8-4d2c-8718-225c90392862, groupInstanceId=None, clientId=calenda
r-sender@97282df6557f (github.com/segmentio/kafka-go), clientHost=/172.26.0.3, sessionTimeoutMs=30000, rebalanceTimeoutMs=30000, supportedProtocols=List(range)) in group calendar_notifications_group with generation 1. (kafka.coo
rdinator.group.GroupMetadata$)
kafka-1             | [2025-01-18 17:14:46,808] INFO Loaded member MemberMetadata(memberId=calendar-sender@97282df6557f (github.com/segmentio/kafka-go)-17dfd5a5-651d-4208-b802-4b1e248e433b, groupInstanceId=None, clientId=calenda
r-sender@97282df6557f (github.com/segmentio/kafka-go), clientHost=/172.26.0.4, sessionTimeoutMs=30000, rebalanceTimeoutMs=30000, supportedProtocols=List(range)) in group calendar_notifications_group with generation 2. (kafka.coo
rdinator.group.GroupMetadata$)
kafka-1             | [2025-01-18 17:14:46,809] INFO Loaded member MemberMetadata(memberId=calendar-sender@97282df6557f (github.com/segmentio/kafka-go)-78f42651-1ede-4363-b03f-da4dfe27420a, groupInstanceId=None, clientId=calenda
r-sender@97282df6557f (github.com/segmentio/kafka-go), clientHost=/172.26.0.3, sessionTimeoutMs=30000, rebalanceTimeoutMs=30000, supportedProtocols=List(range)) in group calendar_notifications_group with generation 3. (kafka.coo
rdinator.group.GroupMetadata$)
kafka-1             | [2025-01-18 17:14:46,810] INFO Loaded member MemberMetadata(memberId=calendar-sender@97282df6557f (github.com/segmentio/kafka-go)-2c155902-0271-43a7-aee2-154c9e28b90b, groupInstanceId=None, clientId=calenda
r-sender@97282df6557f (github.com/segmentio/kafka-go), clientHost=/172.26.0.4, sessionTimeoutMs=30000, rebalanceTimeoutMs=30000, supportedProtocols=List(range)) in group calendar_notifications_group with generation 4. (kafka.coo
rdinator.group.GroupMetadata$)
kafka-1             | [2025-01-18 17:14:46,811] INFO Loaded member MemberMetadata(memberId=calendar-sender@4a0c3dad9f1e (github.com/segmentio/kafka-go)-9c582f1b-896d-4bde-930f-e2b7f4bc8756, groupInstanceId=None, clientId=calenda
r-sender@4a0c3dad9f1e (github.com/segmentio/kafka-go), clientHost=/172.26.0.3, sessionTimeoutMs=30000, rebalanceTimeoutMs=30000, supportedProtocols=List(range)) in group calendar_notifications_group with generation 6. (kafka.coo
rdinator.group.GroupMetadata$)
kafka-1             | [2025-01-18 17:14:46,812] INFO Loaded member MemberMetadata(memberId=calendar-sender@43d99c85c040 (github.com/segmentio/kafka-go)-0b86b592-f792-4052-80c4-8f7abeb97b8a, groupInstanceId=None, clientId=calenda
r-sender@43d99c85c040 (github.com/segmentio/kafka-go), clientHost=/172.26.0.4, sessionTimeoutMs=30000, rebalanceTimeoutMs=30000, supportedProtocols=List(range)) in group calendar_notifications_group with generation 7. (kafka.coo
rdinator.group.GroupMetadata$)
kafka-1             | [2025-01-18 17:14:46,812] INFO Loaded member MemberMetadata(memberId=calendar-sender@3a98ac6a8d93 (github.com/segmentio/kafka-go)-f5ca1e69-d1d8-48b2-8d17-caabc6c1b966, groupInstanceId=None, clientId=calenda
r-sender@3a98ac6a8d93 (github.com/segmentio/kafka-go), clientHost=/172.26.0.3, sessionTimeoutMs=30000, rebalanceTimeoutMs=30000, supportedProtocols=List(range)) in group calendar_notifications_group with generation 8. (kafka.coo
rdinator.group.GroupMetadata$)
kafka-1             | [2025-01-18 17:14:46,813] INFO Loaded member MemberMetadata(memberId=calendar-sender@3a98ac6a8d93 (github.com/segmentio/kafka-go)-a51de96c-7999-48c2-8ddb-6182979c8942, groupInstanceId=None, clientId=calenda
r-sender@3a98ac6a8d93 (github.com/segmentio/kafka-go), clientHost=/172.26.0.4, sessionTimeoutMs=30000, rebalanceTimeoutMs=30000, supportedProtocols=List(range)) in group calendar_notifications_group with generation 9. (kafka.coo
rdinator.group.GroupMetadata$)
kafka-1             | [2025-01-18 17:14:46,813] INFO Loaded member MemberMetadata(memberId=calendar-sender@3a98ac6a8d93 (github.com/segmentio/kafka-go)-d3c385b2-04ad-4f95-b174-e7e4cd0efe5c, groupInstanceId=None, clientId=calenda
r-sender@3a98ac6a8d93 (github.com/segmentio/kafka-go), clientHost=/172.26.0.3, sessionTimeoutMs=30000, rebalanceTimeoutMs=30000, supportedProtocols=List(range)) in group calendar_notifications_group with generation 10. (kafka.co
ordinator.group.GroupMetadata$)
kafka-1             | [2025-01-18 17:14:46,814] INFO Loaded member MemberMetadata(memberId=calendar-sender@85d6971d8f84 (github.com/segmentio/kafka-go)-b834e6d9-095f-462a-b0f3-e6be39e4062d, groupInstanceId=None, clientId=calenda
r-sender@85d6971d8f84 (github.com/segmentio/kafka-go), clientHost=/172.26.0.3, sessionTimeoutMs=30000, rebalanceTimeoutMs=30000, supportedProtocols=List(range)) in group calendar_notifications_group with generation 11. (kafka.co
ordinator.group.GroupMetadata$)
kafka-1             | [2025-01-18 17:14:46,814] INFO Loaded member MemberMetadata(memberId=calendar-sender@609429beef55 (github.com/segmentio/kafka-go)-4294d677-d3e4-447e-8cf8-63998d623286, groupInstanceId=None, clientId=calenda
r-sender@609429beef55 (github.com/segmentio/kafka-go), clientHost=/172.26.0.4, sessionTimeoutMs=30000, rebalanceTimeoutMs=30000, supportedProtocols=List(range)) in group calendar_notifications_group with generation 12. (kafka.co
ordinator.group.GroupMetadata$)
kafka-1             | [2025-01-18 17:14:46,815] INFO Loaded member MemberMetadata(memberId=calendar-sender@ccb6cfcf3c8d (github.com/segmentio/kafka-go)-f521fd17-e321-4b65-86fc-f12683c6dd28, groupInstanceId=None, clientId=calenda
r-sender@ccb6cfcf3c8d (github.com/segmentio/kafka-go), clientHost=/172.26.0.4, sessionTimeoutMs=30000, rebalanceTimeoutMs=30000, supportedProtocols=List(range)) in group calendar_notifications_group with generation 13. (kafka.co
ordinator.group.GroupMetadata$)
kafka-1             | [2025-01-18 17:14:46,815] INFO Loaded member MemberMetadata(memberId=calendar-sender@0c92c06c9329 (github.com/segmentio/kafka-go)-422b1b1a-6295-4c3c-a424-0d815d9e013d, groupInstanceId=None, clientId=calenda
r-sender@0c92c06c9329 (github.com/segmentio/kafka-go), clientHost=/172.26.0.3, sessionTimeoutMs=30000, rebalanceTimeoutMs=30000, supportedProtocols=List(range)) in group calendar_notifications_group with generation 14. (kafka.co
ordinator.group.GroupMetadata$)
kafka-1             | [2025-01-18 17:14:46,816] INFO Loaded member MemberMetadata(memberId=calendar-sender@86849df84755 (github.com/segmentio/kafka-go)-31906faa-e52c-491c-a026-4842d31a6a65, groupInstanceId=None, clientId=calenda
r-sender@86849df84755 (github.com/segmentio/kafka-go), clientHost=/172.26.0.3, sessionTimeoutMs=30000, rebalanceTimeoutMs=30000, supportedProtocols=List(range)) in group calendar_notifications_group with generation 15. (kafka.co
ordinator.group.GroupMetadata$)
kafka-1             | [2025-01-18 17:14:46,816] INFO Loaded member MemberMetadata(memberId=calendar-sender@f7c964a5be4c (github.com/segmentio/kafka-go)-3bc8c0d0-e515-4934-91ea-1f10e6e666e1, groupInstanceId=None, clientId=calenda
r-sender@f7c964a5be4c (github.com/segmentio/kafka-go), clientHost=/172.26.0.3, sessionTimeoutMs=30000, rebalanceTimeoutMs=30000, supportedProtocols=List(range)) in group calendar_notifications_group with generation 16. (kafka.co
ordinator.group.GroupMetadata$)
kafka-1             | [2025-01-18 17:14:46,817] INFO Loaded member MemberMetadata(memberId=calendar-sender@9c9035194c9f (github.com/segmentio/kafka-go)-498f28dd-c67a-423f-b52a-b7a48893fe25, groupInstanceId=None, clientId=calenda
r-sender@9c9035194c9f (github.com/segmentio/kafka-go), clientHost=/172.26.0.3, sessionTimeoutMs=30000, rebalanceTimeoutMs=30000, supportedProtocols=List(range)) in group calendar_notifications_group with generation 17. (kafka.co
ordinator.group.GroupMetadata$)
kafka-1             | [2025-01-18 17:14:46,818] INFO Loaded member MemberMetadata(memberId=calendar-sender@9c9035194c9f (github.com/segmentio/kafka-go)-73c21e76-4d85-4e15-816a-c738d5157dcb, groupInstanceId=None, clientId=calenda
r-sender@9c9035194c9f (github.com/segmentio/kafka-go), clientHost=/172.26.0.4, sessionTimeoutMs=30000, rebalanceTimeoutMs=30000, supportedProtocols=List(range)) in group calendar_notifications_group with generation 18. (kafka.co
ordinator.group.GroupMetadata$)
kafka-1             | [2025-01-18 17:14:46,818] INFO Loaded member MemberMetadata(memberId=calendar-sender@b0eca0c30dce (github.com/segmentio/kafka-go)-ae4aaa66-0a11-4ce0-bea3-f7a36df74f51, groupInstanceId=None, clientId=calenda
r-sender@b0eca0c30dce (github.com/segmentio/kafka-go), clientHost=/172.26.0.4, sessionTimeoutMs=30000, rebalanceTimeoutMs=30000, supportedProtocols=List(range)) in group calendar_notifications_group with generation 19. (kafka.co
ordinator.group.GroupMetadata$)
kafka-1             | [2025-01-18 17:14:46,820] INFO Loaded member MemberMetadata(memberId=calendar-sender@b0eca0c30dce (github.com/segmentio/kafka-go)-a319879e-11b9-4603-a142-7042c899bac8, groupInstanceId=None, clientId=calenda
r-sender@b0eca0c30dce (github.com/segmentio/kafka-go), clientHost=/172.26.0.3, sessionTimeoutMs=30000, rebalanceTimeoutMs=30000, supportedProtocols=List(range)) in group calendar_notifications_group with generation 20. (kafka.co
ordinator.group.GroupMetadata$)
kafka-1             | [2025-01-18 17:14:46,828] INFO [GroupCoordinator 1]: Loading group metadata for calendar_notifications_group with generation 20 (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:46,839] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-43 in 187 milliseconds for epoch 46, of which 72 milliseconds was spent i
n the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,839] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 187 milliseconds for epoch 46, of which 187 milliseconds was spent
in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,840] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 188 milliseconds for epoch 46, of which 187 milliseconds was spent
in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,841] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 189 milliseconds for epoch 46, of which 188 milliseconds was spent
in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,843] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-31 in 191 milliseconds for epoch 46, of which 190 milliseconds was spent
in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,845] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 192 milliseconds for epoch 46, of which 191 milliseconds was spent
in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,846] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 193 milliseconds for epoch 46, of which 192 milliseconds was spent
in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,847] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 193 milliseconds for epoch 46, of which 193 milliseconds was spent i
n the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,848] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 195 milliseconds for epoch 46, of which 195 milliseconds was spent
in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:46,849] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 196 milliseconds for epoch 46, of which 196 milliseconds was spent i
n the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka-1             | [2025-01-18 17:14:47,018] INFO [GroupCoordinator 1]: Dynamic Member with unknown member id joins group calendar_notifications_group in Stable state. Created a new member id calendar-sender@b0eca0c30dce (git
hub.com/segmentio/kafka-go)-50bfd080-9309-4ff3-bcac-7a6388eeb076 for this member and add to the group. (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:47,022] INFO [GroupCoordinator 1]: Preparing to rebalance group calendar_notifications_group in state PreparingRebalance with old generation 20 (__consumer_offsets-43) (reason: Adding new
member calendar-sender@b0eca0c30dce (github.com/segmentio/kafka-go)-50bfd080-9309-4ff3-bcac-7a6388eeb076 with group instance id None; client reason: not provided) (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:14:47,119] INFO [QuorumController id=1] CreateTopics result(s): CreatableTopic(name='test-notifications', numPartitions=1, replicationFactor=1, assignments=[], configs=[]): TOPIC_ALREADY_EXIS
TS (Topic 'test-notifications' already exists.) (org.apache.kafka.controller.ReplicationControlManager)
kafka-1             | [2025-01-18 17:15:16,839] INFO [GroupCoordinator 1]: Member calendar-sender@b0eca0c30dce (github.com/segmentio/kafka-go)-a319879e-11b9-4603-a142-7042c899bac8 in group calendar_notifications_group has failed
, removing it from the group (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:15:16,848] INFO [GroupCoordinator 1]: Stabilized group calendar_notifications_group generation 21 (__consumer_offsets-43) with 1 members (kafka.coordinator.group.GroupCoordinator)
kafka-1             | [2025-01-18 17:15:16,878] INFO [GroupCoordinator 1]: Assignment received from leader calendar-sender@b0eca0c30dce (github.com/segmentio/kafka-go)-50bfd080-9309-4ff3-bcac-7a6388eeb076 for group calendar_noti
fications_group for generation 21. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)

